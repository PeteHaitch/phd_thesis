---
title: "Bioinformatics analysis of whole-genome bisulfite-sequencing data"
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: ../latex/header.tex
  html_document:
    keep_md: true
bibliography: ../latex/phd_thesis.bib
---

\chapter{Bioinformatics analysis of whole-genome bisulfite-sequencing data}\label{chap:wgbs_bioinformatics_analysis}

\begin{chapabstract}
I explain the bioinformatics analysis of whole-genome bisulfite-sequencing data, concentrating on the most widely used \emph{methylC-seq} protocol. All data used in my thesis were generated using this protocol.

There are four fundamental steps in the analysis of bisulfite-sequencing data:

\begin{enumerate}
  \item Data quality control checks
  \item Read mapping and post-processing of mapped reads
  \item Methylation calling
  \item Downstream analyses
\end{enumerate}

This chapter focuses on steps 1-3, while Chapter \ref{chap:wgbs_downstream_analyses} addresses the wide variety of analyses available at Step 4. Steps 1 and 2 will be familiar to anyone who has analysed high-throughput sequencing data, but each requires a twist to work with bisulfite-sequencing data. Step 3 is obviously unique to assays of DNA methylation, but there are similarities to variant calling from DNA sequencing.

The chapter concludes by introducing the `methtuple` software, a unique methylation caller for extracting methylation patterns at tuples of methylation loci. \texttt{methtuple} is critical for work in later chapters on co-methylation (Chapter \ref{chap:co-methylation}) but has wider application in facilitating downstream analyses of bisulfite-sequencing data.
\end{chapabstract}

\section{Data quality control checks}\label{sec:data_qc}

The first step in any analysis of high-throughput sequencing data is to perform a quality control check of the data. Much of this is done visually by comparing summary graphs of the current sample(s) to previous 'good' samples. As such, much of data quality control checking relies on the judgement of the analyst.

The `FastQC` software is a very useful tool for performing this first step ([http://www.bioinformatics.babraham.ac.uk/projects/fastqc/](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/)). It produces summary graphs of many key measures such as base quality scores, read length distribution and sequence contamination. `FastQC` is a general purpose tool for performing quality control checks of high-throughput sequencing data. This means that some of its output must be interpreted with caution for bisulfite-sequencing data. For example, `FastQC` will report a warning (resp. error) if the relative frequency of the four nucleotides differ by more than $10\%$ (resp. $20\%$). As noted in the `FastQC` documentation, such a warning/error should be ignored for bisulfite-sequencing data, owing to the inherent bias in their sequence composition.

Perhaps the most important quality control of bisulfite-sequencing data is the identification and removal of contaminating sequences. `FastQC` will screen a subset of the reads against a list of known, common contaminants such as adapter sequences. When sequencing is performed using the widely used Illumina technology, adapter sequences must be ligated to the ends of each DNA molecule in the library. The adapters do not contain the biological sequence of interest, however, the sequencer can 'read into' the adapter sequence, particularly when using paired-end sequencing of short DNA fragments such as those frequently created in bisulfite-sequencing libraries. This means that some reads are chimeras that contain the biological sequence of interest (from the sample) and junk sequence (from the adapters). This contamination needs to be removed for two reasons:

1. Reads containing adapter contamination will generally not map to the reference genome, meaning these reads are needlessly wasted.
2. If they do map, then this will result incorrect inferences; the 'garbage in, garbage out' maxim.

Using a tool such as `Trim Galore!` ([http://www.bioinformatics.babraham.ac.uk/projects/trim_galore/](http://www.bioinformatics.babraham.ac.uk/projects/trim_galore/)) or `cutadapt` \citep{Martin:2011va}, the reads can be _trimmed_ to remove these contaminants. Reads might also be trimmed to remove low quality sequencing cycles, which are common at the 3' end of reads, although this isn't as essential as trimming to remove contaminants.

\section{Read mapping and post-processing of mapped reads}\label{sec:mapping_and_post-processing}

Read mapping is complicated by the bisulfite-treatment of the DNA. Following bisulfite-treatment, the DNA fragments are mostly composed of three bases rather than four, which means there are many more sequence mismatches between a read and its true mapping location. Simply using standard read mapping software and allowing for more mismatches would result in many reads mapping to multiple locations in the reference genome. Instead, a field of read mapping software dedicated to bisulfite-sequencing data has developed. Several review articles have summarised and compared the various approaches \citep[e.g.,]{Chatterjee:2012ft, Krueger:2012ks, KundeRamamoorthy:2014fj}.

These bisulfite-sequencing read mappers take one of two approaches:

1. Methylation-aware mismatch penalties.
2. _In silico_ bisulfite-conversion of reads and reference genomes.

While methylation-aware mappers provide the highest efficiency, these suffer from a bias whereby methylated reads are preferentially mapped over unmethylated reads \citep{Krueger:2012ks}. This biases downstream inference and means that these mappers are generally less popular.

_In silico_ bisulfite-conversion mappers convert all cytosines to thymines (resp. guanines to adenines) of the forward (resp. reverse) strand from the reference genome. They then take each read and create two _in silico_ bisulfite-converted versions of it[^2_reads]: the CT-read replaces all residual thymines with cytosines and the GA-read replaces all residual guanines with adenines. The CT-read is mapped against the CT-genome and the GA-read is mapped against the GA-genome using a standard mapping tools such as `Bowtie1` \citep{Langmead:2009fv}, `Bowtie2` \citep{Langmead:2012jh} or `bwa`  \citep{Li:2009fi, Li:2010bl}[^non_directional].

[^2_reads]: Two versions are made because we don't know _a priori_ from which of the two strands the read originated.

[^non_directional]: If the data were generated using a non-directional protocol, then each read of the CT-read and the GA-read are mapped to both of the CT-genome and GA-genome, resulting in four mapping steps per read.

Depending on the exact settings used, the mapper reports the 'best' location of each read with respect to the two reference genomes. It reports the original sequence of the read in the output file so that the methylation status of each position can be inferred by comparing it to the corresponding reference sequence.

_In silico_ bisulfite-conversion mappers avoid the bias inherent in the methylation-aware mappers because all reads, regardless of methylation status, 'look the same' to the mapper. However, they do suffer from a slight loss in mapping efficiency \citep{Krueger:2012ks}.

Table \ref{tab:bs-seq_mappers} list some popular bisulfite-sequencing read mappers, which have been selected to highlight the variety of underlying mapping software used by these tools.

\begin{table}[h]
\centering
\begin{tabulary}{\textwidth}{LLL}
\toprule
Name      & Reference                                            & Underlying mapping software \\ \midrule
Bismark   & \citet{Krueger:2011eb}                              & Bowtie1 or Bowtie2          \\
bwa-meth  & \citet{Pedersen:2014wt}                             & bwa-mem                     \\
BSMAP     & \citet{Xi:2009bd}                                   & SOAP                        \\
Novoalign & \url{http://www.novocraft.com/products/novoalign/} & Novoalign                   \\ \bottomrule
\end{tabulary}
\caption{Four popular bisulfite-sequencing read mappers, selected to highlight the variety of underlying mapping software used by these tools.}
\label{tab:bs-seq_mappers}
\end{table}

Each of these aligners can report the output in the standard Sequence Alignment/Map format, `SAM`, or its binary equivalent, `BAM` \citep{Li:2009ka}. However, there is no agreed upon standard in the `SAM` specification for encoding the data specific to bisulfite-sequencing, which means that each mapper does this in a slightly different way. This complexity makes it difficult for downstream analysis tools to support the output of different mapping software.

Read mapping is not perfect and produces both false positive and false negative results. False positives are due to reads mapped to the wrong location and reads mapped to multiple locations with equal mapping scores. False negatives are reads that are not mapped to any location; these reads are effectively lost from any downstream analysis. The parameter settings used by the mapping software determine the false positive and false negative rates.

There are biological and technical reasons why mapping against a reference genome can produce these errors. Biologically, if the sample contains sequences that are too genetically divergent from the reference genome then these sequences will be difficult, even impossible, to map. A particularly problematic class of sequences are those from repetitive regions of the genome. These repetitive sequences will map to multiple locations in the reference genome equally well. Furthermore, the number of times these repetitive sequences occur differs between the reference genome and sample's genome.

Technically, reads from Illumina sequencing are often too short to resolve the mapping location of these repetitive sequences. Resolving the mapping location of repetitive sequences can be achieved by using other sequencing technologies, such as Pacific Biosciences SMRT technology \citep{Flusberg:2010hra}, which produces longer reads.

Another source of technical error in read mapping is really due to sequencing error. A sequencing error can transform a uniquely mapping read to one that maps equally well to multiple locations or, worse still, a read that maps uniquely to a single, but incorrect, location. Sequencing errors can also corrupt a read so badly that it no longer can be mapped, which leads to that read being a false negative. In practice, most people try to mitigate these problems through their choice of parameters used by the read mapping software.

Ideally, mapping software assigns the degree of confidence it has that the read is correctly mapped via a mapping quality score (`mapQ`). In theory, reads might be down-weighted in downstream analyses based on the mapping quality score. However, these mapping quality scores are often poorly calibrated, particularly for methylC-seq data, which makes them less useful. `Bismark` \citep{Krueger:2011eb}, a popular bisulfite-sequencing mapping software, only recently introduced mapping quality scores (`v0.12.1`, released in April 2014).

The above problems are general challenges of read mapping and are not specific to bisulfite-sequencing data, although the reduced complexity of bisulfite-sequencing reads exacerbates these issues. The difficulty of mapping to repetitive regions of the genome is a particularly frustrating one for  bisulfite-sequencing data. Repetitive sequences, such as LINEs and SINEs, are typically methylated in order to prevent transcription and are often of interest to researchers studying DNA methylation. The low mapping efficiencies of these regions means that there is often limited or less reliable data for these elements from bisulfite-sequencing data.

\subsection{PCR duplicates}\label{sec:pcr_duplicates}

PCR amplification of the input DNA is a common step in creating a library for high-throughput sequencing. PCR amplification is often required to ensure that there is a sufficient amount of DNA for the sequencer to properly work. Unfortunately, it can introduce biases into the library that result in some molecules being over-represented or under-represented compared to their true frequency. This means that when we sequence the library that we might sequence multiple fragments that are all copies of the same original piece of DNA, which gives a biased sampling of our sample's genome. These multiply-sequenced fragments are called _PCR duplicates_.

In bisulfite-sequencing data, PCR duplicates containing a methylation locus can result in a biased estimate of the methylation level at that locus. This is because the sequenced reads do not accurately represent the true methylation levels of the sample.

There is generally no way to tell if a read is truly a PCR duplicated based on the sequencing data alone.

There is generally no way to tell based on sequencing data if a read is truly a PCR duplicate. However, it is relatively easy to identify suspected PCR duplicates (which are almost always inaccurately referred to as 'PCR duplicates'[^pcr_dup]). Software to identify PCR duplicates includes the `MarkDuplicates` function that is a part of the `Picard` software ([http://broadinstitute.github.io/picard/](http://broadinstitute.github.io/picard/)), the `rmdup` function that is a part of the `SAMtools` software \citep{Li:2009ka} and `SAMBLASTER` \citep{Faust:2014hf}. These software all use mapped reads from a `SAM` or `BAM` file as input.

[^pcr_dup]: The distinction between suspected PCR duplicates and true PCR duplicates is rarely made, possibly because the phrase is so clunky. Suspected PCR duplicates are almost always referred to as PCR duplicates with the implicit assumption that the reader is aware that these very likely include false positive calls. Consistent with the literature, I will use the term PCR duplicates when I refer to reads identified as PCR duplicates by some software. I will use _true_ PCR duplicates when I need to distinguish the two concepts.

Roughly speaking, these tools will flag reads with identical start and end co-ordinates as being suspected PCR duplicates. This will inevitably lead to some false positives because reads may have identical co-ordinates yet not be PCR duplicates. The false positive rate is a particular problem when a subset of the genome is sequenced at high coverage, such as in RRBS. This can be thought of as an example of the pigeonhole principle, which states that if we have $m$ containers (positions where a read can start) and $n > m$ items (reads), then at least one container must contain more than one item (at least one position must have more than one read starting there).

We could make this mathematically more precise, but it doesn't give us a simple answer to the question, 'should we remove possible PCR duplicates from bisulfite-sequencing data?'. The unsatisfactory answer is, 'it depends'. A rule of thumb is that provided the average or median sequencing coverage of the 'genome' is less than the fragment length[^pcr_fragment_length] then we expect few false positive calls.

[^pcr_fragment_length]: For single-end data, the 'fragment length' in these calculations is the read length.

In practice, this means that for whole-genome sequencing data we can be fairly confident that suspected PCR duplicates are _true_ PCR duplicates. However, for targetted sequencing, such as RRBS or amplicon sequencing, we are much less confident and may remove some of our signal if we remove possible PCR duplicates. Instead, for RRBS we might exclude regions with an "abnormally" high sequencing coverage \citep{Krueger:2012ks}. For amplicon sequencing we often can't afford to exclude possible PCR duplicates if, for example, the aim is to identify rare epialleles by very deep sequencing of a small region.

\subsection{M-bias}\label{sec:m-bias}

Ideally, the probability that a base is called as methylated should be independent of the sequencing cycle. \citet{Hansen:2011gu} found that this is not the case and that in fact there is considerable bias towards the start (5') and end (3') of reads. They called this _M-bias_.

M-bias can be identified by plotting the read-position methylation level ($rpml$), which is the proportion of reads that are methylated at each read-position, as a function of read-position. These $rpml$ are computed separately for each methylation type and, for paired-end sequencing data, separately for _read-1_ and _read-2_. If there is no M-bias then this plot should be a horizontal line. A 'bend' or 'spike' in this plot is evidence of M-bias. Furthermore, these lines, which indicate the average level of methylation in the sample for that methylation type, should be at the same level for _read-1_ and _read-2_, although we see this is often not quite the case. Figure \ref{fig:ADS_M-bias} is the M-bias plot for the _ADS_ sample from the _Lister_ dataset[^datasets], which shows significant CpG M-bias at the start of _read-2_ and some noise at the start of _read-1_.

[^datasets]: See Chapter \ref{chap:datasets} for a description of this sample.

\begin{figure}[!htb]
\centering
\centering
\includegraphics[width=\textwidth]{../figures/ADS_M-bias.pdf}
\caption{M-bias plot for the \emph{ADS} sample from the \emph{Lister} dataset. Each of \emph{read-1} (R1) and \emph{read-2} (R2) are plotted separately.}
\label{fig:ADS_M-bias}
\end{figure}

If a sample is processed over multiple batches, then M-bias estimation (and methylation calling) should be performed separately for each batch and then combined, or in some manner that is 'batch aware'. For example, two libraries with DNA derived from the same cell line, but with separate library preparations and sequencing runs, will likely suffer from batch effects due to differences in the library preparations or differences with the sequencing runs. Unfortunately, the person analysing the data doesn't always know all the sample processing steps that may have introduced such batch effects and so these can be hard to deal with in practice.

The strongest source of M-bias in Illumina whole-genome bisulfite-sequencing data is at the 5' end of _read-2_, which sequences the 3' end of the DNA fragment. Because the DNA fragment is often shorter than the sum of the read lengths, the 3' end of the fragment often contains adapter sequence and other 'junk' sequence. The adapter sequence may contain cytosine bases, which will be misinterpreted as evidence of methylation \citep{Krueger:2012ks}. Similarly, "fill-in cytosines" are used in the construction of RRBS libraries to repair the ends of DNA fragments after cleavage by MspI; these would also be misinterpreted as evidence of methylation \citep{Krueger:2012ks}. Another source of M-bias is incomplete or uneven bisulfite-conversion.

\subsubsection{Estimating M-bias}\label{sec:estimating_m-bias}

Estimating M-bias and incorporating it into the methylation calling can be done using two different strategies:

1. Compute the M-bias from the aligned reads, then call methylation events. The methylation calling should include filters to remove the detected M-bias (along with any other additional filters). This strategy requires two passes over the `SAM/BAM` file - one to compute the M-bias and one to do the methylation calling. This is the approach used by `bismark_methylation_extractor` \citep{Krueger:2011eb} and `Bis-SNP` \citep{Liu:2012ge}.
2. Call methylation events but retain the read-position of each methylation event. Compute the M-bias from this first file and then filter out methylation events that suffer from M-bias. This strategy requires only a single pass over the `SAM/BAM` file but requires additional information to be stored alongside the methylation calls which is then followed by a pass over the file containing the methylation calls. This is the approach taken by `BSmooth` \citep{Hansen:2012gr}.

I find the first strategy conceptually simpler, and easier to program, so use it in my methylation calling software, `methtuple`, described in Section \ref{section:methtuple}).

In theory, the M-bias could be estimated during the alignment step or during another processing step, such as sorting or marking PCR duplicates, to avoid an additional pass over the `SAM/BAM` file.

A somewhat subtle point is that M-bias should only be estimated from reads that are actually going to be used for methylation calling. Suppose that M-bias is highly correlated with some other quality metric, such as base quality, so that positions with M-bias also have low base quality[^bq_mbias]. If you already intend to ignore read-positions with a base quality less than some threshold in your methylation calling, then it makes sense to also ignore these positions when estimating M-bias, otherwise you will overestimate the effect of M-bias and unnecessarily exclude read-positions in your methylation calling. Unfortunately, perhaps the most widely used software for estimating M-bias, `bismark_methylation_extractor` \cite{Krueger:2011eb}, does not allow the user to exclude certain reads or read-positions when estimating M-bias.

[^bq_mbias]: This is very often the case since the 3' end of reads are typically of lower quality and also frequently suffer from M-bias.

\subsubsection{Pre-trimming reads destroys the one-to-one relationship between read-position and sequencing cycle}\label{sec:pre-trimming_reads}

Trimming reads prior to alignment (_pre-trimming_), such as using `Trim Galore!` ([http://www.bioinformatics.babraham.ac.uk/projects/trim_galore/](http://www.bioinformatics.babraham.ac.uk/projects/trim_galore/)) to remove adapter sequence from reads, destroys the one-to-one relationship between the sequencing cycle and the read-position. This causes a minor problem when computing M-bias because we no longer know whether the read-position is identical to the sequencing cycle. Soft-clipping or hard-clipping reads of their adapter sequence _during_ the alignment avoids this issue, because the clipping information (should be) preserved in the `CIGAR` string[^cigar].

[^cigar]: Not all software properly handles the information in the `CIGAR` string, particularly for soft-clipped reads. This is a shortfall of the downstream tools and not of aligner-based clipping _per se_, but is nonetheless an issue in practice. `bwa-meth` \citep{Pedersen:2014wt} and `LAST` \citep{Kieibasa:2011do} both perform well without pre-trimming of reads because they can soft-clip reads on the fly whereas other bisulfite-sequencing aligners, such as `Bismark` \citep{Krueger:2011eb}, cannot soft-clip reads and so require that reads are pre-trimmed.

The M-bias plot is based on the read-position from the aligned data and not the sequencing cycle (which isn't directly available in the `SAM/BAM` file). If the reads have been pre-trimmed, then each read-position in the M-bias plot will therefore contain data from multiple sequencing cycles, which can amplify or mask the M-bias signal.

For example, suppose we performed $100$ bp single-end sequencing and pre-trimmed the first 20 bp of $90\%$ of the reads. Then, read-position $80$ will comprise $10\%$ sequencing cycle $80$ and $90\%$ sequencing cycle $100$. It is very likely that sequencing cycle $100$ suffers more from M-bias than does cycle $80$, and so this will appear in the M-bias plot as M-bias at read-position $80$.

\begin{figure}[!htb]
\centering
\centering
\includegraphics[width=\textwidth]{../figures/E18VA_M-bias.pdf}
\caption{M-bias plot for the E18VA sample from the EPISCOPE dataset. Each of \emph{read-1} (R1) and \emph{read-2} (R2) are plotted separately. For CpGs in \emph{read-1}, we see noise at the start of the read, followed by a downward slope in the M-bias, which ends with a spike. For CpGs in \emph{read-2}, we see a downward spike at the start of the read following by a gradual increase in the M-bias curve, with a spike at read-position 101 and a spike at the last read-positions for all methylation types. The spike at read-position 101 is also evidence, albeit to a lesser extent, in \emph{read-1}. This position should be ignored in downstream analyses but we do not necessarily also want to ignore read-positions $102-150$ since this would remove one-third of the data.}
\label{fig:E18VA_M-bias}
\end{figure}

The loss of the one-to-one relationship between sequencing cycle and read-position cannot be avoided if reads are pre-trimmed because the trimming information is not preserved. \citet{Hansen:2012gr} suggest a separate M-bias plot for each read-length, which will help mitigate the effect of confounding between read-position and sequencing-cycle[^read_trimming]. However, if trimming is performed during the alignment then all the necessary information is retained and the x-axis of M-bias plots would be 'sequencing cycle' rather than 'read-position', thus avoiding the issue entirely.

[^read_trimming]: This would also require that methylation calling is performed separately for read with different lengths because most methylation callers are unable to deal with different M-bias profiles for different read lengths.

\subsubsection{Identifying M-bias}\label{sec:identifying_m-bias}

In practice, the M-bias curves for each sample are visually inspected to look for evidence of M-bias, i.e., read-positions whose methylation levels are 'too far away' from the vast majority of read-positions. It is rather a subjective decision to make. Two problems that I found when making these decisions were:

1. Maintaining consistency across samples.
2. Determining where to draw the line when there is no dramatic 'spike' in the M-bias.

For example, in Figure \ref{fig:E18VA_M-bias} it is clear that there are problems at the start and end of both _read-1_ and _read-2_, as well as a big problem at read-position 101 in _read-2_. What is less clear is where to draw the line on the gradual decay toward the end of _read-1_ and towards the start of _read-2_. This motivated me to write a few simple functions to perform more systematic processing of M-bias results. These are included in the `MethylationTuples` R package (described in Section \ref{sec:MethylationTuples}) with the `MBias` class, its associated methods, `plot()` and `filter()`, and the helper function `readMBias()`.

For each sample, M-bias is computed separately for each methylation type because the level of methylation varies widely between CG and non-CG methylation types. For paired-end sequencing experiments, it is also done separately for each of _read-1_ and _read-2_ because M-bias is very different for these two mates and also because _read-2_ often has a slightly lower average level of methylation than does _read-1_ (e.g., see Figure \ref{fig:ADS_M-bias}).

In `MethylationTuples`, I use a simple normalisation of the read-position methylation levels ($rpml$). Specifically, the median level of methylation across all read-positions is subtracted from the read-position methylation level to create normalised read-position methylation levels, i.e., $nrpml_{CpG}^{read_1} = rpml_{CpG}^{read_1} - median(rpml_{CpG}^{read_1})$, for CpG methylation in _read-1_.

The `filter()` method identifies read-positions where the $rpml$ differs by more than a given value (`threshold`) from $nrpml$. While it computes these statistics separately for each methylation type and read type, a common `threshold` is used for all methylation types and read types. I tend to use a value of `threshold = 3`, meaning that if the $median(rpml_{CpG}) = 75$, then any read-position with $rpml_{CpG} < 72$ or $rpml_{CpG} > 78$ is flagged as showing evidence of M-bias[^mbias_percentage]. It is currently left to the user to decide whether a read-position should be excluded if it displays evidence of M-bias in a single methylation type or only if it displays evidence across all methylation types. I tend to exclude read-positions that display evidence of M-bias in the methylation type I am working with, which is typically CpG methylation.

[^mbias_percentage]: The M-bias files created by `bismark_methylation_extractor --mbias_only` report the methylation levels as percentages rather than proportions.

\subsubsection{What to do about M-bias?}\label{sec:what_to_do_about_m-bias}

Now that we've found read-positions with M-bias, what can we do about it? Typically, read-positions showing evidence of M-bias are excluded when calling methylation events. In fact, a slightly cruder procedure is typically used whereby the entire ends of reads are removed. For example, suppose we have $100$ bp reads with M-bias observed at positions $1-4, 9, 94, 96-100$, then read-positions $1-9$ and $94-100$ would be ignored when methylation calling.  Both `bismark_methylation_extractor` and `Bis-SNP`, two popular methylation callers, use this method.

This strategy is generally sufficient because M-bias tends to occur as runs of read-positions at the 5' and 3' ends of reads. However, occasionally there are spikes in the M-bias plot, which indicate specific read-positions that we would like to exclude. Figure \ref{fig:E18VA_M-bias} shows an example of such a spike that occurred at read-position 101 in 150 bp reads. Using `bismark_methylation_extractor` we would be forced to either retain this position or to ignore read-positions $101-150$, effectively ignoring one third of the sequencing data, much of it unaffected by M-bias. My `methtuple` software (Section \ref{sec:methtuple}) avoids the unnecessary exclusion of those bases by allowing the user to specify the exact read-positions that she wants to exclude[^methtuple_mbias].

In the datasets I have analysed I've had to ignore up to 30 read-positions per read due to M-bias. Ideally, we would be able to remove the effects of M-bias by accounting for it in methylation calling rather than by simply excluding those read-positions entirely. One idea is to inversely weight methylation calls by the level of M-bias. A downside to this approach is that this would turn an otherwise binary methylation call into a continuous value between $0$ and $1$, with an attendant loss in interpretability. However, we could still compute the ubiquitous $\beta$-values, traditionally defined as the proportion of reads that are methylated at a locus, and use these in downstream inferences, without much loss in interpretation. The bigger problem with this approach is the increased computational complexity and cost, and this is why I have not further pursued this idea.

\subsection{Other biases}\label{sec:other_biases}

There are several other sources of potential bias in analysing bisulfite-sequencing data. These include sequencing and alignment errors, and sequence variation at, or nearby to, methylation loci. A particularly interesting source of bias is due to cellular heterogeneity.

Recent papers using single-cell bisulfite-sequencing \citep{Guo:2013ih, Smallwood:2014kn} have investigated the extent of this cellular heterogeneity by comparing the methylomes of individuals cells that are nominally of the same 'type'. Cellular heterogeneity is particularly problematic when a sample contains multiple cell types.

For example, many studies of DNA methylation use whole blood as the sample tissue due to the ease with which it can be obtained. However, whole blood contains a mixture of cell types, each of which has a distinct methylation profile. This cellular heterogeneity can seriously bias downstream analyses and must be properly accounted for in any study exploring the relationship between differences in DNA methylation and a phenotype \citep{Jaffe:2014gy,Houseman:2014ds}. For example, \citet{Jaffe:2014gy} provide evidence that several reported relationships between age and DNA methylation are likely due to changes in the cell composition of whole blood with age and not due to DNA methylation changes _per se_.

Methods to estimate the cellular heterogeneity bias and adjust for it are available \citep[e.g.,]{Jaffe:2014gy,Houseman:2014ds,Zou:2014gc}, although they have mostly been applied to DNA methylation arrays and not bisulfite-sequencing data. This is not to say that these problems don't exist for sequencing data, merely that these have not been as well-explored.

\section{Methylation calling}\label{sec:methylation_calling}

Methylation calling is the process of calling each sequenced methylation locus as being either methylated or unmethylated[^no_call], as well as determining the _context_ or _type_ of each methylation event (i.e., CpG, CHG or CHH) based on the sequencing data and a reference DNA sequence. In principle, this is a simple process, however, this belies some complications, which I discuss in this section.

[^no_call]: A third possibility is making the call that the 'methylation locus' is not in fact a methylation locus. For example, if the sequenced base at a cytosine in the reference sequence is an adenine or a guanine then this may be evidence that the position is not in fact a methylation locus.

Most bisulfite-sequencing alignment software either performs methylation calling during the alignment process, as done by `Bismark`[^bismark_methylation_extractor], or as a separate step after the alignment and post-processing of the `SAM/BAM` file. An example of the latter is `Bis-SNP` \citep{Liu:2012ge}, which performs methylation calling from bisulfite-sequencing data aligned with the user's choice of alignment software.

[^bismark_methylation_extractor]: `Bismark` also includes a program called `bismark_methylation_extractor`, which, as the name suggests, extracts the methylation calls from the `SAM/BAM` file. So while `Bismark` annotates each base as methylated or unmethylated during the alignment, a secondary step using `bismark_methylation_extractor` is required to make the methylation calls.

\subsection{Methylated or unmethylated?}\label{sec:methylated_or_unmethylated}

All bisulfite-sequencing assays use _reference-based_ methylation calling. This means that they require the specification of a reference DNA sequence that the aligned bisulfite-sequencing data are compared against to infer the methylation state of each sequenced locus. Care must be taken to correctly handle the orientation and strand of the alignment.

When using reference-based methylation calling, the position of the methylation locus is with respect to the reference genome, since then all samples will use a common set of co-ordinates. Some methylation loci cannot be typed using a reference-based approach. For example, unless the genome of the sample is fully known, methylation loci in insertions cannot be distinguished from genetic variation since there is no reference sequence to compare them against.

Prior to methylation calling, each read should be filtered to remove low-quality reads and low quality bases. When using a set of filters, at each step a read either 'survives', and is subjected to the proceeding filter, or 'dies', and is excluded from methylation calling[^read_filters]. Strictly speaking each sequenced nucleotide is assigned a weight in the filtering process, however, in practice, filters are normally first applied to reads and then to all nucleotides within 'surviving' reads. In my own work analysing whole-genome bisulfite-sequencing data, I routinely use the following filters.

A read survives if:

1. The read is mapped (single-end or paired-end) and mapped in the expected orientation (paired-end only).
2. The read is not marked as a PCR duplicate.
3. The read has a mapping quality score greater than some threshold.

A sequenced base survives if:

1. The read-position of the base means that it is unlikely to be affected by M-bias.
2. The base quality score is greater than some threshold.
3. The base is a 'bisulfite mismatch' (e.g., the sequenced base is a C or T at a C in the reference sequence) and not a 'non-bisulfite mismatch' (e.g., the sequenced base is an A or a G at a C in the reference sequence).

[^read_filters]: A read that is not used to estimate $M$ and $U$ may still be used in other analyses, such as estimating copy number variation.

The reference sequence is typically the reference genome used in the alignment step, in spite of the obvious differences between the sample's genome and the reference genome. This reference-based approach may be refined to incorporate genetic differences between the sample and the reference genome. This can be done in several ways:

- Whole-genome sequencing or genotyping of the sample
- Calling genetic variations directly from the bisulfite-sequencing data
- Excluding sites of known genetic variation

\subsubsection{Whole-genome sequencing or genotyping of the sample}\label{sec:wgs_or_genotyping}

The gold-standard is to perform whole-genome DNA sequencing of each sample. This data is then used to form a set of sample-specific methylation loci. However, this approach is also very expensive due to the extra sequencing requirements. A cheaper alternative is to genotype the sample on a genome-wide SNP microarray. This will give very accurate, very cheap genotypes at a large number of loci ($500,000--5,000,000$). However, it obviously cannot identify genetic differences that aren't on the array, such as novel sample-specific genetic variants.

\subsubsection{Calling genetic variations directly from the bisulfite-sequencing data}\label{sec:wgbs_variant_calling}

The next best approach is that implemented in `Bis-SNP` \citep{Liu:2012ge}, which is to call genetic variation from the bisulfite-sequence data itself and to then define a set of sample-specific methylation loci at which to call methylation events. `Bis-SNP` is designed for _directional_ bisulfite-sequencing libraries such as the widely used Illumina whole-genome bisulfite-sequencing protocol.

Certain genetic variants, in particular heterozygous $C$>$T$ SNPs, are more difficult to accurately genotype than others. Unfortunately, $C$>$T$ SNPs are also quite important because they are the most common SNPs in mammals \citep{Liu:2012ge}, mostly occur at CG dinucleotides and, as a result, are easily mis-called as unmethylated cytosines rather than as genetic variants. Fortunately, it is often possible to distinguish $C$>$T$ SNPs from unmethylated cytosines by examining the nucleotide on the opposing strand; if it is a $G$ then the position must be a $C$, if it is a $A$ then it must be a $T$ (see Figure \ref{fig:Bis-SNP}). Other base substitutions are more readily detectable, and insertion and deletion events (indels) may also be called.

\begin{figure}[!htb]
\centering
\centering
\includegraphics[width=\textwidth]{../figures/Bis-SNP.pdf}
\caption{\texttt{Bis-SNP} is able to distinguish unmethylated cytosines (site 1), from cytosine to thymine genetic variants (site 2) and thymine to (unmethylated) cytosine genetic variants (site 3) by examining the reads mapped to the reverse strand. For all three loci, the reads mapped to the forward strand contain a thymine. However, it is the base on the reverse strand that reveals the true genotype. When combined with the reference genome it can be inferred whether the sample's genome, which isn't directly observed, has a genetic variant at that location. This is only possible with bisulfite-data generated using the directional protocol. This figure is adapted from \citet{Liu:2012ge}.}
\label{fig:Bis-SNP}
\end{figure}

To emphasise, `Bis-SNP` provides three important pieces of information that make it almost as good as having whole genome DNA sequencing data on the same sample:

1. Reference-specific methylation loci, i.e., cytosines in the reference genome that are mutated to non-cytosine nucleotides in the sample's genome.
2. Sample-specific methylation loci, i.e., cytosines in the sample's genome that are non-cytosine nucleotides in the reference genome.
3. Other genetic variants that may be used in additional analyses, such as in identifying allele-specific methylation, or to refine the methylation _type_ or _context_ (see below).

Genotype calls made using `Bis-SNP` are less accurate than those from whole-genome DNA sequencing because of the reduced complexity of bisulfite-converted DNA. However, we essentially get to measure DNA variation 'for free' by using `Bis-SNP`, which makes it my preferred approach for incoporating genetic variation into methylation calling. The genetic variant calls made by `Bis-SNP` can also be used to _post-hoc_ filter methylation calls made by other software. I use this approach to filter methylation calls made with `methtuple`.

\subsubsection{Excluding sites of known genetic variation}\label{sec:known_genetic_variation}

The third approach, and arguably the bare minimum, is to call methylation loci using the reference genome and to _post-hoc_ exclude any loci that overlap sites of known genetic variation in the population. For example, we might exclude all cytosines in the reference genome that are also SNPs in dbSNP \citep{Sherry:2001gh}.

This is a conservative approach, as it will remove loci regardless of whether the sample has a genetic variant at that position or not, but it may be a good enough method in some cases. It also obviously requires a database of known variation for the organism being studied, which is the case for commonly studied organisms such as humans and mice.

This approach can obviously only exclude sites of known variation from consideration, and cannot add sample-specific methylation loci. To remove those reference-specific methylation loci that are __not__ found in databases of known genetic variation, we might identify loci in the sample that display a large number of non-C/T bases (resp. non-G/A bases) at a C (resp. G) on the forward (resp. reverse) strand of the reference genome.

\subsection{Determining the context or methylation type}\label{sec:methylation_context}

In addition to determining whether a cytosine is methylated or unmethylated, we also want to determine the _context_ of the cytosine, also known as the _methylation type_. That is, we want to determine whether the cytosine is a CG, CHG or a CHH.

This is done by examining the two nucleotides upstream of the cytosine. It can be done based on the reference sequence, as is done in `Bismark` and `methtuple`, or from the reads themselves. The obvious difficulty with using the reads themselves is if the cytosine occurs at the last or second last position of the read, in which case the context may not be unambiguously determined from the the read alone. Instead, the context may be refined by initially using the reference genome context and then correcting for any sample-specific genetic variants in the two downstream bases.

A further complication occurs when there is a genetic variant in the two nucleotides upstream of the methylation locus. We would like to use the two upstream nucleotides from the sample to infer the sample-specific methylation context, either inferred from each read separately or from a variant calling procedure such as `Bis-SNP`. However, this further complicates the methylation calling and so tools such as `Bismark` derive the context from the reference genome alone.

\section{\texttt{methtuple}}\label{sec:methtuple}

`methtuple` ([https://github.com/PeteHaitch/methtuple](https://github.com/PeteHaitch/methtuple)) is software I wrote to perform methylation calling at genomic tuples that I call _m-tuples_. Before formally defining m-tuples, I first motivate the need for `methtuple`.

\subsection{Motivation}

Most methylation callers, such as `bismark_methylation_extractor` and `Bis-SNP`, perform methylation calling at single methylation loci, which I refer to as 1-tuples. The output file is a table, where each row records the co-ordinates of a cytosine and the number of methylated ($M$) and unmethylated ($U$) reads at that position. Table \ref{tab:1-tuples} is representative of the type of data returned by these programs. The file format is generally tab-delimited plain text, the Browser Extensible Data (BED) format or the Variant Call Format (VCF).

\begin{table}[h]
\centering
\begin{tabular}{@{}lllll@{}}
\toprule
Chromosome & Strand & Position & M & U \\ \midrule
chr1       & $+$      & 100      & 7 & 1 \\
chr1       & $-$      & 101      & 5 & 2 \\
chr2       & $+$      & 400      & 0 & 3 \\
chr2       & $+$      & 450      & 1 & 2  \\ \bottomrule
\end{tabular}
\caption{Example of output for methylation calling at 1-tuples. Each row records the the number of methylated ($M$) and unmethylated ($U$) reads at a 1-tuple. Loci may be stratified by strand, as is done here, in which case most CpGs will have measurements for both the positive and negative strands.}
\label{tab:1-tuples}
\end{table}

While 1-tuples are the basis of most analyses of bisulfite-sequencing data, they do not always give the complete picture of how DNA methylation is acting in the sample. To gain a clearer picture, we can exploit the fact that many bisulfite-sequencing reads contain multiple methylation loci (_m-tuples_) and that each read is from a single cell[^chimeric_reads]. An example of where this is useful is shown in Figure \ref{fig:incomplete_picture_1-tuples} where we have two regions, each with four methylation loci, that have identical methylation calls at 1-tuples yet very different overall methylation patterns. Further examples of where m-tuples are useful are in studying _epialleles_ and _epipolymorphisms_ (Chapter \ref{chap:wgbs_statistical_framework}) and _co-methylation_ (Chapters \ref{chap:co-methylation_review} and \ref{chap:co-methylation}).

[^chimeric_reads]: This ignores chimeric reads, which are created when two DNA fragments ligate to one another during the library preparation. Certain bisulfite-sequencing protocols frequently produce chimeric reads. For example, using the post-bisulfite adapter tagging (PBAT) protocol \citep{Miura:2012fr} with a low input amount of DNA results in a huge number of chimeric reads (personal communication from Felix Krueger). The standard whole-genome bisulfite-sequencing protocol is not known to suffer from this issue.

\begin{figure}[!htb]
\centering
\centering
\includegraphics[width=\textwidth]{../figures/incomplete_picture_1-tuples.pdf}
\caption{Two regions, each with four methylation loci, that have identical $\beta$-values ($\beta = \frac{M}{M + U}$) at 1-tuples yet have very different overall methylation patterns.}
\label{fig:incomplete_picture_1-tuples}
\end{figure}

In order to study these phenomena, we firstly need software that can perform methylation calling at m-tuples, which is why I wrote `methtuple`. When I began my PhD, there was no software capable of calling methylation patterns at arbitrarily sized m-tuples from whole-genome bisulfite-sequencing data. Simultaneous with the development of `methtuple`, there have been some software published with similar functionality. However, none of these do exactly what I require and some have what I consider to be severe deficiencies (Table \ref{tab:other_m-tuple_methylation_callers}). To the best of my knowledge, `methtuple` is the only software that can perform methylation calling at m-tuples from whole-genome bisulfite-sequencing data.

\begin{table}[h]
\centering
\begin{tabulary}{\textwidth}{LLLL}
\toprule
Software           & Reference                                & Input                                              & Limitations                                                                \\ \midrule
methclone & \citet{Li:2014ei}                       & \texttt{Bismark} \texttt{BAM}                                  & Unable to install \\
methpat  & \url{https://github.com/bjpop/methpat} & Output of \texttt{bme} & Designed for amplicons not whole-genome data.                                                                                 \\
DMEAS    & \citet{He:2013cj}                       & Output of \texttt{bme} & Windows operating system only. Perl code only available as PDF file.             \\
\bottomrule
\end{tabulary}
\caption{Other software for methylation calling at m-tuples and their limitations. Abbreviations: \texttt{bme} =  \texttt{bismark\_methylation\_extractor}.}
\label{tab:other_m-tuple_methylation_callers}
\end{table}

\subsection{m-tuples}\label{sec:m-tuples}

I define an m-tuple to be a tuple of $m = 1, 2, \ldots$ methylation loci. I refer to $m$ as the _size_ of the tuple. In principle, the $m$ loci that make up an m-tuple could come from anywhere in the genome, but it makes most sense to require that the $m$ loci be close to one another. In fact, I generally require that an m-tuple consists of $m$ _adjacent_ methylation loci[^adjacent]. An equivalent way of describing an m-tuple as comprising adjacent methylation loci is one where the number of intervening loci is zero ($NIL = 0$). There are three reasons that I focus on m-tuples with $NIL = 0$:

1. Quantity: From a sequence containing $l$ methylation loci there are $l - \text{m} + 1$ $NIL = 0$ m-tuples. In contrast, there are $\binom{l}{\text{m}}$ $NIL \geq 0$ m-tuples. Obviously, $\binom{l}{\text{m}} \geq l - \text{m} + 1$, with strict inequality if $m \neq 1$ or $m \neq l$.
2. Interpretability: Results for m-tuples with $NIL = 0$ are simpler to interpret than when allowing $NIL \geq 0$. This is discussed in Chapter \ref{chap:co-methylation}.
3. Measurability: We cannot observe m-tuples where the methylation loci are far apart due to the read length limitations of the Illumina sequencing technology. This is true even when $NIL = 0$ but is more of an issue if we allow $NIL \geq 0$.

[^adjacent]: Two methylation loci are adjacent if there is no methylation loci in between the pair. For example, `CGCG` and `CGTTACG` both contain two adjacent CpGs (the intervening `TTA` in the second sequence does not include a CpG). In contrast, the first and last CpG in the sequence `CGTCGTCG` are __not__ adjacent, since the intervening sequencing, `TCGT` include a CpG. Note that in situations where we are only interested in studying CpGs, we define 'methylation loci' to mean 'CpGs'. Therefore the sequence `CGTCTTCG` contains two adjacent methylation loci; while there is a `C` in the intervening sequence, `TCTT`, it is a CHH not a CpG.

Generally, when referring to m-tuples I implicitly mean those with $NIL = 0$; I will explicitly use the notation $NIL \geq 0$ when I wish to make clear that there may be intervening methylation loci in the m-tuple. The default option of `methtuple` is to produce m-tuples with $NIL = 0$ unless the `--all-combinations` flag is set[^nil0].

[^nil0]: Actually, while `methtuple` tries to produce m-tuples with $NIL = 0$ it can't guarantee this because it would require looking up the reference genome sequence for each m-tuple (this is avoided for computational simplicity). This is only really an issue with paired-end sequencing, as is made clear in the examples of Figures \ref{fig:methtuple_example1}, \ref{fig:methtuple_example2}, \ref{fig:methtuple_example3} and \ref{fig:methtuple_example4}. Some _post-hoc_ filtering of the m-tuples will generally be required in order to remove those m-tuples with $NIL > 0$.

I require that each methylation call at an m-tuple comes from a single read. There are $2^{m}$ possible methylation calls at an m-tuple. For example, at a 1-tuple there are $2^{1}$ possible methylation calls --- $M$ or $U$; at a 3-tuple there are $2^{3} = 8$ possible methylation calls --- $MMM$, $MMU$, $MUM$, $MUU$, $UMM$, $UMU$, $UUM$ or $UUU$.

For each m-tuple, I also define the intra-pair distance (_IPD_) as the vector containing the $(m - 1)$ pair-wise distances (measured in bp) between methylation loci in the m-tuple. For example, the 2-tuple (`chr7:+:145`, `chr7:+:163`) has $IPD = (163 - 145) = (18)$. The 5-tuple (`chr2:-:560`, `chr2:-:570`, `chr2:-:572`, `chr2:-:588`, `chr2:-:612`) has $IPD = (570 - 560, 572 - 570, 588 - 572, 612 - 588) = (10, 2, 16, 24)$. The IPD vector of a 1-tuple is undefined.

To illustrate several of the above-mentioned concepts, suppose we sequence a region of the genome containing five methylation loci with three paired-end reads (`A`, `B` and `C`), shown in Figure \ref{fig:methtuple_example1}.

\begin{figure}[!htb]
\centering
\centering
\includegraphics[width=0.6\textwidth]{../figures/methtuple_example1.pdf}
\caption{Diagram of three-paired end reads (\texttt{A}, \texttt{B} and \texttt{C}) mapping to a region containing five methylation loci (\texttt{1} $--$ \texttt{5}). The suffix \texttt{\_1} or \texttt{\_2} indicates whether it is \emph{read-1} or \emph{read-2}, respectively.}
\label{fig:methtuple_example1}
\end{figure}

If we are interested in 1-tuples, Figure \ref{fig:methtuple_example2} shows what we would obtain from each read by running `methtuple`. The result is identical regardless of whether the `--all-combinations` flag is set.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{../figures/methtuple_example2.pdf}
\caption{1-tuples produced for each read for the toy example in Figure \ref{fig:methtuple_example2}.}
\label{fig:methtuple_example2}
\end{figure}

If we are interested in 3-tuples, Figure \ref{fig:methtuple_example3} shows what we would obtain from each read by running `methtuple` in its default mode. A few things to note:

- Read-pair `A` sequences all three (= 5 - 3 + 1) adjacent 3-tuples
- Read-pair `B` sequences none of the adjacent 3-tuples but does 'erroneously' construct two 3-tuples from pairs of non-adjacent loci. This happens because m-tuples are created independently from each read-pair; effectively, read-pair `B` is unaware of methylation locus `3`. Depending on the downstream analysis, the user may wish to _post-hoc_ filter out these m-tuples with non-adjacent loci.
- The twice-sequenced methylation loci in read-pair `C`, `2` and `3`, are only counted once.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{../figures/methtuple_example3.pdf}
\caption{3-tuples produced for each read for the toy example in Figure \ref{fig:methtuple_example2}.}
\label{fig:methtuple_example3}
\end{figure}

Finally, Figure \ref{fig:methtuple_example4} shows the output if we were to analyse 3-tuples but with the `--all-combinations` flag set.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{../figures/methtuple_example4.pdf}
\caption{3-tuples produced for each read for the toy example in Figure \ref{fig:methtuple_example2} when the \texttt{--all-combinations} flag is set.}
\label{fig:methtuple_example4}
\end{figure}

With current sequencing technology we are limited to extracting m-tuples that span no more than $200-250$ bp. This obviously affects the size of m-tuples that we can study. Figure \ref{fig:Lister_CpGs_per_read} shows the number of CpGs per read for the Lister dataset (see Chapter \ref{chap:datasets} for a description of the Lister dataset). Longer reads, and paired-end reads, contain more methylation loci and so are more informative for analyses using m-tuples. This can be seen by comparing, for example, the _ADS_ and _HSF1_ samples. Samples sequenced more deeply will have more reads per m-tuple, although this can't be seen in these plots since they are normalised by sequencing depth.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{../figures/Lister_CpGs_per_read.pdf}
\caption{Number of CpGs per read for the Lister dataset.}
\label{fig:Lister_CpGs_per_read}
\end{figure}

\subsection{Implementation}\label{sec:methtuple_methods}

`methtuple` performs methylation calling for a single `BAM` file generated by `Bismark`. The user is required to specify the size of the tuples (`--m`), and the methylation type (`--methylationType`) for each run of the program. There are many useful options to filter reads and read-positions. Apart from the standard quality filters, `methtuple` is careful when processing paired-end reads to only count the base from one of the reads in any overlapping paired-end reads to avoid double-counting these overlapping bases. `methtuple` also allows the user to filter out specific read-positions rather than wholesale filtering of the ends of reads. This is particularly useful for samples where there is a 'spike' in the M-bias plot, such as that shown in Figure \ref{fig:E18VA_M-bias}. Such a 'spike' can be filtered out without also being forced to also filter out additional upstream read-positions that are not affected by M-bias.

`methtuple` is written in Python and uses the `pysam` ([https://github.com/pysam-developers/pysam/](https://github.com/pysam-developers/pysam/)) module to parse the `BAM` file. It is compatible with both Python2 and Python3. To improve performance, I provide a helper script to split the sample by chromosome and process each chromosome in parallel ([https://github.com/PeteHaitch/methtuple/blob/master/helper_scripts/run_methtuple.sh](https://github.com/PeteHaitch/methtuple/blob/master/helper_scripts/run_methtuple.sh)). This helper script makes extensive use of `GNU parallel` \citep{Tange:2011ty}. While Python-level parallel processing is desirable, this `GNU parallel`-based approach was simpler to implement and sufficient for my purposes.

`methtuple` is currently limited to processing files produced by `Bismark` due to its reliance on the `Bismark`-specific tags `XM`, the "methylation call string",  `XR`, the "read conversion state for the alignment", and `XG`, the "genome conversion state for the alignment" ([http://www.bioinformatics.bbsrc.ac.uk/projects/bismark/Bismark_User_Guide.pdf](http://www.bioinformatics.bbsrc.ac.uk/projects/bismark/Bismark_User_Guide.pdf)). It could be extended to work with other bisulfite-sequencing aligners. However, due to the eccentricities of each aligner, such an extension would have to be aligner-specific and is therefore a considerable undertaking. Each extension would require that tags analogous to the `XR`, `XG` and `XM` tags can be generated from the given `BAM` file. In the case of the `XM` tag, this would likely require that the reference genome is parsed in parallel with the `BAM` file, adding considerable computational overhead. Perhaps the easiest option would be to add a script that 'Bismark-ifies' the original `BAM` file. Since all my data are aligned with Bismark, or were converted to Bismark's `BAM` format, I have not yet had need to pursue this line of work.

The output format of `methtuple` is tab-delimited plain text, optionally compressed with `gzip` or `bzip2`. Figure \ref{fig:3-tuples} shows an example of the output for 3-tuples.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{../figures/3-tuples.pdf}
\caption{Example output of \texttt{methtuple} for 3-tuples.}
\label{fig:3-tuples}
\end{figure}

\subsection{Performance}

I have used `methtuple` to perform methylation calling at CpG m-tuples, $m = 1, \ldots, 8$, for over 50 whole-genome bisulfite-sequencing samples. Figure \ref{fig:methtuple_runtime} shows the distribution of running times and Figure \ref{fig:methtuple_memory} the maximum memory usage across all the samples from the EPISCOPE, Lister and Ziller datasets. For each sample, each chromosome was processed using a single core on one of the shared-use servers in the Bioinformatics Division (see Table \ref{tab:unices} in the Appendix for details of these machines).

The running time of `methtuple` is proportional to the number of reads mapped to the chromosome, which is proportional to the length of the chromosome and its ploidy. The running time is largely independent of the tuple size (`-m`). The variation in running times within a chromosome is due to the number of reads generated per sample and the length of the reads, where the length of a paired-end read is defined as the sum of the mates' lengths. Samples with more reads take longer to process and samples sequenced with longer reads take longer because these contain more m-tuples.

The maximum memory usage is not strictly proportional to chromosome length. It is instead driven by the number and density of CpGs on the chromosome.  For example, chromosome 19, which has the highest CpG density of all the autosomes in the human genome, requires far more memory than chromosome 18, which has less than half the CpG density of chromosome 19 (see Table \ref{tab:cpg_density_hg19}). The relationship between the maximum memory usage and the tuple size (`-m`) is complex; more data have to be retained as `-m` increases, thus increasing the memory usage, but fewer reads contain tuples of that size and so there aren't as many m-tuples or observations on these to count and retain. Therefore, memory usage is relatively constant across values of `-m` for a given chromosome. The obvious exception is for the results labelled `2ac`, which used the `--all-combinations` flag in conjunction with `-m 2`. This means that all 2-tuples with $NIL \geq 0$ were computed and there are many, many more CpG 2-tuples with $NIL \geq 0$ than there are with $NIL = 0$, hence the increase in memory usage.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{../figures/methtuple_runtime.pdf}
\caption{The running times are the `User time' reported by \texttt{GNU time} converted from seconds to minutes. The suffix `ac' on the tuple size means that the option \texttt{--all-combinations} was set. Note that the reported $49$ samples separately counts each of the Ziller sequencing runs (see Chapter \ref{chap:datasets} for details).}
\label{fig:methtuple_runtime}
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{../figures/methtuple_memory.pdf}
\caption{The maximum memory usage is the `Maximum resident set size' reported by \texttt{GNU time} converted from kilobytes to gigabytes. These values are divided by four to fix bug in how \texttt{GNU time} reports the maximum memory usage (\url{https://bugzilla.redhat.com/show_bug.cgi?id=703865}). The suffix `ac' means that the option \texttt{--all-combinations} was set. Note that the reported $49$ samples separately counts each of the Ziller sequencing runs (see Chapter \ref{chap:datasets} for details).}
\label{fig:methtuple_memory}
\end{figure}

```{r autosomal_cpg_density_hg19, echo = FALSE, eval = TRUE, message = FALSE, results = "asis"}
library(xtable)
x <- read.table("../data/wgbs_bioinformatics_analysis/CpG_density_hg19.txt",
                header = TRUE, stringsAsFactors = FALSE)
xt <- xtable(x, caption = "Percentage of dinucleotides that are CpGs for each chromosome in the human reference genome (hg19).", label = "tab:cpg_density_hg19")
align(xt) <- rep("c", ncol(x) + 1)
digits(xt) <- 2
print(xt, booktabs = TRUE, comment = FALSE, tabular.environment = "longtable", floating = FALSE, include.rownames = FALSE)
```

\subsection{Availability}

`methtuple` is open-source software released under the MIT licence and available from [https://github.com/PeteHaitch/methtuple](https://github.com/PeteHaitch/methtuple).
