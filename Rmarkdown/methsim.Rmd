---
title: "A simulation model of DNA methylation data"
author: "Peter Hickey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: ../latex/header.tex
  html_document:
    keep_md: true
bibliography: ../latex/phd_thesis.bib
---

# Chapter overview


# Introduction

Simulation studies play a vital role in the development, validation and benchmarking of methods in applied statistics. Simulation is necessary when there is a lack of real datasets with well-known outcomes that we would otherwise use to assess a method's performance. While simulated data can never fully capture the richness of "real" data, we can learn a lot about a method by studying how it performs when applied to simulated data.

While we may sometimes be able to design an experiment with known outcomes via the use of controls, both positive and negative, this is not always possible in genomics. One reason for this is the cost of performing a well-designed control experiment. Why spend your time and money on an experiment where you "know the answer" when you could be spending that same time and money on investigating something new? Another reason is that in genomics we are often working with cutting-edge technology that is so new that we lack the technological and biological knowledge to even design such a control experiment.

The key advantage of using simulated data over real data is that we know the truth _a priori_. Moreover, we can manipulate the truth via parameters in the simulation model and can examine how a method performs under a variety of scenarios. And this manipulation is cheap, a mere matter of changing parameters and re-running a piece of software, which means that we can investigate a broad range of plausible scenarios.

Simulation studies can provide many insights into the performance of a method. At the most basic level, if a method fails to work or performs poorly when applied to simulated data, then it is very unlikely to work well when applied to real data. We can also identify which scenarios are "easy", ones where most methods are able to identify the truth, and scenarios under which certain methods perform better than others.

Simulation studies can also tell us about the plausibility of hypothesised stochastic or mechanistic models of a phenomenon. By simulating data from the proposed model and comparing it to the real data we can identify shortcomings in the model that we can later refine.

In the field of genomics, almost all papers proposing a new method will include a simulation study and perhaps a comparison to existing methods, if these exist. There are a few key criteria when designing a simulation method:

1. Realism: The simulated data must be "similar" to the real data. While this is obvious, it is also often hard to pin down or agree upon what constitutes "similar enough".
2. Cost: It should be fast and cheap to simulate data. The most common use of simulation models in applied statistics is to repeatedly generate datasets under a range of parameter settings. This requires that each simulation is fast and computationally cheap, otherwise it will be prohibitive to analyse the full space of scenarios. An exception to this rule may occur when the simulation model is used to test a proposed mechanistic or stochastic model of a phenomenon, such as in studies of molecular dynamics. Even then, however, the cost of a simulation should be less than the cost of performing the equivalent experiments, otherwise the simulation is generally not worth the effort.
3. Usability: There __must__ be a software implementation. Simulation models exist to be simulated from; a simulation model without an implementation is next to useless. The implementation should give the user easy access to the key  parameters and have sensible default settings. The output of the software should be in a standard format or readily convertible to a simple, manipulable format.

The above discussion refers to the general use of simulation models, particularly in applied statistics. I now turn my attention to the need for simulation models in the study of DNA methylation. Whole-genome bisulfite-sequencing remains an expensive assay, costing a few thousand dollars per sample (human) at the time of writing. Understandably, studies using WGBS have been from well-funded research groups focusing on "sexy" biology rather than on efforts to generate extensively-validated control datasets.

The statistical methodology to analyse such experiments lags somewhat behind the ability to generate the data, as is common in genomics. Nonetheless, more statistical methods are being published seeking to address common research questions such as identifying differential methylation. However, because of the lack of "gold-standard" datasets, it is not clear which of these perform well for common experimental designs and research questions. Many of these published methods feature a simulation study in the accompanying paper, but, as we will shortly see, these simulations are woefully inadequate, unrealistic and vary between papers. In order to perform a proper benchmarking of these methods we require a realistic simulation model, something that I have attempted to address with my software, `methsim`, which I describe in this chapter.

# Background + literature review

Simulated bisulfite-sequencing data may be used in the comparison of strategies for the alignment and processing of bisulfite-converted reads, or in the comparison of downstream analysis methods. Simulation methods for bisulfite-sequencing data may choose to simulate the individual sequencing reads, unaligned or aligned, or some summary measure of methylation, such as $\beta$-values. The former is required for the comparison of different alignment strategies whereas the latter is typically used by developers of downstream analysis methods, such as differential methylation callers, since this is often all that is required to run these methods. Moreover, simulated reads must be aligned and processed before they can be used in comparisons of downstream analysis methods, which is often not of direct relevance in comparisons of these tools.

## Methods for simulating bisulfite-sequencing reads

All of the available methods for simulating bisulfite-sequencing reads are designed for the comparison of alignment strategies. These are not suitable for comparisons of downstream analysis methods.

`Sherman` ([http://www.bioinformatics.babraham.ac.uk/projects/sherman/](http://www.bioinformatics.babraham.ac.uk/projects/sherman/)) is software to simulate bisulfite-sequencing reads, including various 'contaminants', such as SNPs, basecall errors and sequence artefacts as `FASTQ` files. The simulated reads are designed for comparing the performance of different alignment strategies. It has many parameters, of which the ones relevant to our discussion of simulating realistic DNA methylation data are `-CG` and `-CH`, the bisulfite conversion rates for CG and CH methylation loci, respectively. These are set by the user with values between $0$ and $100$. Reads are simulated by sampling from the user-specified reference genome. When a read contains a CG (resp. CH) locus, it is randomly assigned as being converted (unmethylated) with probability `-CG` / 100 (resp. `-CH` / 100).  

While suitable for comparing alignment strategies, `Sherman` produces data that is not suitable for use in comparing downstream analysis methods. All CG (resp. CH) loci have an average $\beta$-value of `-CG` (resp. `-CG`) regardless of the genomic context, which we know to be inconsistent with real data. Furthermore, the methylation state of each methylation locus is independent, which is clearly inconsistent with the strong co-methylation observed in real data.

`FastqToBS` ([http://users.dimi.uniud.it/~nicola.prezza/projects.html](http://users.dimi.uniud.it/~nicola.prezza/projects.html)) uses the same strategy as `Sherman`.

`DNemulator` ([http://www.cbrc.jp/dnemulator/README.html](http://www.cbrc.jp/dnemulator/README.html)) uses a slightly more sophisticated simulation strategy to simulate `FASTQ` files for use in comparing alignment strategies for bisulfite-sequencing data. `DNemulator` does this with three separate routines, `fasta-methly-sim`, `fasta-polymorph` and `fasta-bisulf-sim`:

1. `fasta-methyl-sim` converts cytosines in the reference genome (`FASTA` file) to a character indicating the methylation level of that locus: `C` represents $0\%$ methylated, `c` represents $10\%$ methylated, `d` represents $20\%$ methylated, `v` represents $50\%$ methylated and `t` represents $100\%$ methylated. Each of these conversions has a different probability in the CG and CH contexts.
2. `fasta-polymorph` simulates a polymorphic, diploid genome based on the modified reference sequence created by `fasta-methyl-sim`.
3. `fasta-bisulf-sim` simulates reads by sampling from the simulated genome created by `fasta-polymorph`. Read are simulated with bisulfite-conversion error and sequencing error.

The reads simulated by `DNemulator` will result in $\beta$-values that have more context-dependence than those resulting from reads generated by `Sherman`, `FastqToBS` or `BSsim`. However, methylation events are still generated independently of one another, which means there is no co-methylation in the simulated data. Therefore, reads simulated by `DNemulator`, while suitable for comparing alignment strategies, are not suitable for comparing downstream analysis methods.

`BSsim` ([http://122.228.158.106/BSSim/](http://122.228.158.106/BSSim/) and used in \cite{Xie:2014ez}), uses a similar strategy to `DNemulator`.

## Methods for $\beta$-values

Methods to describe:

- [ ] \cite{Feng:2014iq}
- [ ] \cite{Lacey:2013iy}
- [ ] \cite{Sofer:2013bk}
- [ ] \cite{Xu:2013eg}
- [ ] \cite{Chen:2014jb}
- [ ] \cite{Park:2014ho}
- [ ] \cite{Dolzhenko:2014bo}
- [ ] \cite{Xie:2014ez}
- [ ] Others?




# Methodology

`methsim` is designed for simulating data for downstream analyses, and uses a hybrid strategy that is capable of creating raw, unaligned reads or summary measures, such as $\beta$-values, from the same simulation run.

# Implementation

# Case study

# Discussion of findings

# Conclusions
