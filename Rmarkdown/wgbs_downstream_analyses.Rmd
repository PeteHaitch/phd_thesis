---
title: "Downstream analyses of whole-genome bisulfite-sequencing data"
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: ../latex/header.tex
  html_document:
    keep_md: true
bibliography: ../latex/phd_thesis.bib
---

\chapter{Downstream analyses of whole-genome bisulfite-sequencing data}\label{chap:wgbs_downstream_analyses}

\begin{chapabstract}
This chapter discusses methods for the \emph{downstream analysis} of bisulfite-sequencing data. Downstream analyses proceed the processing of the raw data (Chapter \ref{chap:wgbs_bioinformatics_analysis}) to address the scientific questions of interest. Most downstream analyses are based on methylation counts at 1-tuples, however, there is growing interest in analyses based on methylation patterns at m-tuples. I discuss the statistical questions underlying these downstream analyses, paying particular attention to those based on m-tuples (m $> 1$) since these have received less attention in the literature.

A barrier to analyses based on m-tuples has been a lack of software. To help eliminate this barrier, I develop \texttt{MethylationTuples}, an R package for managing, analysing and visualising methylation patterns at m-tuples. \texttt{MethylationTuples} complements \texttt{methtuple} (Chapter \ref{chap:wgbs_bioinformatics_analysis}) by providing a framework for the manipulation and analysis of methylation patterns at m-tuples. I describe methods available in \texttt{MethylationTuples} for the downstream analysis of whole-genome bisulfite-sequencing data.
\end{chapabstract}

\section{Methods based on 1-tuples}

The majority of downstream analysis methods use methylation patterns at 1-tuples, i.e. $\mathbf{m} = (m_{1}, \ldots, m_{i}, \ldots, m_{N_{loci}})$ and $\mathbf{u} = (u_{1}, \ldots, u_{i}, \ldots, u_{N_{loci}})$[^not_beta_values]. Methods based on 1-tuples have been developed to address a variety of scientific questions including testing for differential methylation (Section \ref{sec:differential_methylation}), testing for differentially variable methylation (Section \ref{sec:variable_methylation}) and identifying regulatory regions of the genome (Section \ref{sec:epigenome_segmentation}).

[^not_beta_values]: It is insufficient to use $\bm{\beta} = \frac{\mathbf{m}}{\mathbf{m} + \mathbf{u}}$ because the conversion to $\beta$-values loses information about the precision with which each methylation locus is measured (i.e. the sequencing depth, $\mathbf{d} = \mathbf{m} + \mathbf{u}$).

\subsection{Differential methylation}\label{sec:differential_methylation}

By far the most common analysis of bisulfite-sequencing data is to identify differentially methylated cytosines (DMCs) and differentially methylated regions (DMRs). Consequently, there has been a flurry of methods proposed for identifying differential methylation \citep[e.g.,][]{Akalin:2012cm, Chen:2013eh, Chen:2014jb, Dolzhenko:2014bo, Gokhman:2014cp, Jaffe:2012gx, Lacey:2013iy, Lister:2009hy, Rijlaarsdam:2014hp, Sofer:2013bk, Xie:2014ez, Feng:2014iq, Hebestreit:2013ko, Sun:2014fk, Park:2014ho, Hansen:2012gr}. \citet{Robinson:2014jz} recently reviewed methods for identifying DMCs and DMRs and so I give but an overview of this important topic.

\subsubsection{Experimental design}\label{sec:experimental_design}

In any analysis of differential methylation, we want the DMCs and DMRs to be both _biologically_ and _statistically_ significant; it's no good if all the differences are simply due to technical artefacts or random fluctuations. Key to ensuring biological relevance is good experimental design, such as the use of _replicates_ in each experimental group. A distinction is often made in the literature between _technical replicates_ and _biological replicates_. Briefly, biological replicates are experimental units that all undergo the same treatment and are used to estimate the within-group variability of the treatment. Technical replicates are repeated measurements of the same experimental unit, perhaps with slight variations in the sample preparation, and are used to estimate the variability of the sample preparation and measurement process.

The boundary between biological and technical replication is not always clear. For example, \citet{Lister:2009hy} state that, "For each cell type, two __biological__ replicates were performed with cells of different passage number [emphasis added]". I contend that these are better defined as technical replicates since each replicate came from the same cell line, underwent passaging under near-identical conditions and differ only by the number of cell passages in each media[^cell_passaging].

[^cell_passaging]: In the case of IMR90 cell line, the first replicate, IMR90_r1, underwent 4 cell passages and the second replicate, IMR90_r2, underwent 5 cell passages. In the case of the H1 cell line, the first replicate, H1_r1, underwent 25 passages in the first media and 9 passages in the second media, and the second replicate, H1_r2, underwent 27 passages in the first media and 5 passages in the second media.

Initial experiments with whole-genome bisulfite-sequencing rarely had replicates of any kind or, if they did, these were pooled prior to analysis (e.g., the analysis of the H1 and IMR90 cell lines in \citet{Lister:2009hy}). Simply pooling replicates and analysing as if they were a single sample ignores all variability between replicates and should not be used.

Technical variability is ideally orthogonal to the biological variability, but this rarely occurs in practice. Indeed, high-throughput sequencing experiments are particularly susceptible to batch effects, and other sources of unwanted variation, that can swamp the biological variation of interest \citep{Leek:2010jq}. This again emphasises the importance of good experimental design, with randomisation, replication and the use of positive and negative controls.

\subsection{Differentially methylated cytosines}\label{sec:dmcs}

A differentially methylated cytosine (DMC) is one where the true methylation level, $B_{i}$, is different between experimental conditions. This is typically framed as a test of the mean levels of methylation at the locus in each group[^mean]. Suppose we have a two-group experiment and let $B_{i, j_{k}}$ denote the true methylation level of the $i^{th}$ methylation locus for samples in the $k^{th}$ group ($k = 0, 1$). We wish to test the null hypothesis of $H_{0}: B_{i, j_{0}} = B_{i, j_{1}}$ against the alternative hypothesis $H_{1}: B_{i, j_{0}} \neq B_{i, j_{1}}$. As such, identifying DMCs boils down to identifying differences in means, for which there is an enormous body of statistical literature. This problem can be viewed as a 'stand-alone' test, such as a t-test, or framed as a regression problem to allow for the inclusion of additional covariates.

[^mean]: This could alternatively be framed as a test of the median methylation level at the locus in each group (or of some other location parameter of the distribution of methylation levels).

Regardless of the statistical test used, all attempts to identify DMCs from whole-genome bisulfite-sequencing data must pay a large multiple-hypothesis testing penalty. Correcting for multiple hypothesis testing is standard practice in the analysis of genomics data, but the number of tests, in this case approximately 25 million, is at least one order of magnitude greater than what is commonly tested in other genomics experiments[^multiple_testing]. Various methods have been used to correct for this multiple testing, as illustrated in Table \ref{tab:multiple_testing}.

[^multiple_testing]: For example, there are approximately 20,000 tests in studies of differential gene expression and two million tests in genome-wide association studies.

\begin{table}[h]
\centering
\caption[Proposed multiple hypothesis testing procedures]{Methods proposed for adjusting for the multiple hypothesis testing performed in an analysis of DMCs. Several papers use describe their analysing as performing a ``false discovery rate adjustment'' or ``false discovery rate correction'' without explicitly stating what they are doing or citing a reference. One paper uses the Bonferonni correction, leading to a very conservative analysis since this correction aims to control the family-wise error rate.}
\label{tab:multiple_testing}
\begin{tabulary}{\textwidth}{LL}
\toprule
Method                                       & Used by                                                                            \\ \midrule
\citet{Benjamini:1995ws}                      & \citet{Akalin:2012cm, Jaffe:2012gx, Lacey:2013iy, Rijlaarsdam:2014hp, Sofer:2013bk} \\
\citet{Wang:2011cw}                           & \citet{Akalin:2012cm}                                                               \\
``False discovery rate correction/adjustment'' & \citet{Dolzhenko:2014bo, Gokhman:2014cp, Lister:2009hy, Xie:2014ez}                 \\
\citet{Storey:2007cp}                         & \citet{Jaffe:2012gx}                                                                \\
\citet{Benjamini:2001ho}                      & \citet{Sofer:2013bk, Hebestreit:2013ko}                                             \\
``Bonferonni adjustment''                      & \citet{Feng:2014iq}                                                                 \\ \bottomrule
\end{tabulary}
\end{table}

One thing to note, however, is that the _effective_ number of tests is fewer than the actual number of tests. This is because the methylation levels at neighbouring loci are correlated (see Chapters \ref{chap:co-methylation_review} and \ref{chap:co-methylation}), which means that tests of differential methylation are generally positively correlated, thus reducing the effective number of independent tests. The classical Benjamini-Hochberg procedure also controls the false discovery rate under certain forms of positive dependence \citep{Benjamini:2001ho}.

While there have been reports of DMCs resulting in a phenotypic difference \citep[e.g.,][]{Furst:2012gh}, DMCs are mostly tested as a prelude to the identification of differentially methylated regions (DMRs). Moreover, with approximately 25 million CpGs in the human genome, not to mention the many, many more non-CpG cytosines, it is an optimist who aims for the reliable detection of DMCs from whole-genome bisulfite-sequencing experiments. This will remain true while sample sizes can be counted on one or two hands and the average sequencing depth is $10\times$ to $30\times$.

Several software packages are now available for identifying DMCs. Most are limited to analysing two-group experiments. Rather than directly analysing the $\mathbf{m}$ and $\mathbf{u}$, these software generally make additional modelling assumptions, such as the beta-binomial model (Section \ref{sec:beta-binomial_models}), and/or perform some transformation of the data, such as smoothing of the $\beta$-values (Section \ref{sec:transformations}).

`DSS` \citep{Feng:2014iq}, `BiSeq` \citep{Hebestreit:2013ko}, `MOABS` \citep{Sun:2014fk}, `methylSig` \citep{Park:2014ho} and `RADmeth` \citep{Dolzhenko:2014bo} all use a beta-binomial hierarchical model of DNA methylation, although the exact details differ considerably between packages. `DSS` and `MOABS` use empirical Bayes methods to estimate parameters whereas `methylSig`, `BiSeq` and `RADmeth` use maximum likelihood estimation. `BiSeq` and `methlySig` also perform spatial smoothing of the data.

The statistical test used to identify DMCs in these regression models is variously a Wald test (`BiSeq`, `DSS`), a likelihood ratio test (`methlySig`, `RADmeth`) or based on the Bayesian credible interval of the difference in methylation between the two groups (`MOABS`).

Not all software for identifying differential methylation are designed for identifying DMCs. For example, both `bsseq` \citep{Hansen:2012gr} and `Aclust` \citep{Sofer:2013bk} are methods explicitly designed for identifying differentially methylated regions rather than DMCs.

\subsection{Differentially methylated regions}

A differentially methylated region (DMR) is a region of the genome where there are multiple cytosines with evidence of differential methylation. Importantly, not all cytosines in the region need necessarily be genome-wide statistically significant DMCs. Rather, the idea is that a DMR might capture a weaker but broader difference in methylation. For example, it may be more biologically relevant to identify a broad region with a consistent, albeit small, difference in methylation than it is to identify individual cytosines with large differences in methylation.

There are two very different strategies for identifying DMRs:

1. Using regions that are defined _a priori_, which are then tested for differential methylation. Such regions might be CpG islands \citep[e.g.,][]{Huang:1999fs,Doi:2009ky}[^array]; MspI restriction fragments \citep[e.g.,][]{Stockwell:2014fq}; a predefined genomic feature, such as a gene promoters or transcription factor binding sites; or general predefined bins \citep[e.g., 100 bp bins used by][]{Park:2014ho}.
2. Using data-driven regions, such as those defined from an analysis of DMCs, which are then tested for differential methylation.

[^array]: Both these examples are from microarray studies, but the same idea can be applied to sequencing studies.

The former is much simpler to analyse but is limited in its ability to discover novel DMRs. It is also hampered because the correct unit or scale for differential methylation may not be known for the experiment.

The latter offers the opportunity to identify novel regions that are subject to differential methylation. Included in this is the opportunity to discover the scale over which differential methylation acts. However, valid statistical inference of these regions is far more challenging.

\subsubsection{Using \emph{a priori} regions}

The idea of testing for differential methylation at _a priori_ defined regions is relatively straightforward. Suppose we have a two-group experiment and let $\widebar{B}_{r, j_{k}}$ be the true average level of methylation for the $r^{th}$ region for samples in the $k^{th}$ group ($k = 0, 1$). The null hypothesis is $H_{0}: \widebar{B}_{r, j_{0}} = \widebar{B}_{r, j_{1}}$ against the alternative hypothesis $H_{1}: \widebar{B}_{r, j_{0}} \neq \widebar{B}_{r, j_{1}}$.

We might estimate $\widebar{B_{r}^{k}}$ by the group-wise average of the sample-wise weighted average of $\beta$-values for all methylation loci in the region, where the weights are proportional to the sequencing coverage. Identifying differential methylation at _a priori_ defined regions simply boils down to identifying differences in means, just as is the case for testing for DMCs. Again, this problem can be viewed as a 'stand-alone' test, such as a t-test, or framed as a regression problem to allow for the inclusion of additional covariates.

The above description brushes over some technicalities, such as how to handle CpGs with insufficient sequencing coverage. An alternative approach for testing _a priori_ defined regions for differential methylation is offered by `BiSeq` \citep{Hebestreit:2013ko}.

\subsubsection{A hierarchical procedure for testing \emph{a priori} defined regions for differential methylation}

`BiSeq` \citep{Hebestreit:2013ko} uses a hierarchical procedure to test for differential methylatoin at _a priori_ defined regions. To begin, `BiSeq` first defines _CpG clusters_ by identifying CpGs that are within a user-specified genomic distance of one another and that have sufficient sequencing coverage across the set of samples[^biseq_alternative]. While there is clearly a 'data-driven' component to these cluster definitions, I reserve the use of 'data-driven regions' for those that are based on the methylation levels of loci rather than their genomic co-ordinates.

[^biseq_alternative]: As an alternative to creating these CpG clusters, \citet{Hebestreit:2013ko} also suggest using the target regions of the assay, such as MspI fragments in the case of RRBS.

Once these clusters are defined, the $\beta$-values in each cluster are smoothed for each sample using a local binomial likelihood smoother. This procedure will create a smoothed $\beta$-value for each CpG, even those with insufficient sequencing coverage. Then, for each CpG, `BiSeq` fits a beta regression model[^not_beta-binomial] to the smoothed $\beta$-values, which is tested for evidence of differential methylation at that cytosine (i.e. a test of whether the cytosine is a DMC).

Based on these P-values, `BiSeq` then use a hierarchical testing procedure to control the false discovery rate at both the cluster-level and locus-level. This method is based on several papers by Yoav Benjamini and colleagues \citep{Benjamini:1997fh, Benjamini:2001ho, Benjamini:2006gd, Benjamini:2007cm}. It aims to first control the false discovery rate at the cluster-level and then refines the signal by trimming non-DMCs from those clusters that have been declared as differentially methylated. Finally, these differentially methylated clusters are _post hoc_ filtered to ensure they are _consistent_, i.e. that the differences in methylation are in the same direction.

[^not_beta-binomial]: This is different to the beta-binomial regression framework described in Section \ref{sec:beta-binomial_models}.

\subsubsection{Using data-driven regions}

Methods for identifying _data-driven_ DMRs are statistically _ad hoc_. The most common approach is to scan the genome for clusters of DMCs and declare these to be DMRs. The initial scan for DMCs will typically use a relaxed statistical significance threshold (i.e. not necessarily genome-wide significant). Notably, many of these methods do not include a formal statistical test of differential methylation at the region-level \citep[e.g.,][]{Lister:2009hy, Lister:2011kg, Hansen:2011gu, Feng:2014iq}.

For example, \citet{Hansen:2011gu} start by testing all CpGs for differential methylation and retain all those with a P-value in the lowest $5\%$. They then declare putative DMRs to be contiguous runs of such CpGs that are within a given distance of one another and with "all differences in the same direction" (i.e. the region is consistent). These putative DMRs may be subject to further filtering, such as requiring that they contain a minimum number of CpGs and span a minimum number of bases, and the merging of nearby putative DMRs into a single putative DMR \citep{Hansen:2011gu}.

It is challenging to perform valid statistical inference of differential methylation at these data-driven regions. We must be careful when 'double-dipping' into the data, whereby the same data are being used to define the regions as are being used to test their significance. These regions have been _selected_ because loci in these region display a difference and therefore tests of whether the region has a difference are biased towards rejecting the null hypothesis.

The challenges of valid statistical inference at such data-driven regions are not unique to the problem of testing for DMRs. Similar problems arise in the analysis of chromatin immunoprecipitation sequencing (ChIP-seq) experiments \citep{Schwartzman:2011to, Lun:2014gn} and in the field of signal processing \citep{Schwartzman:2011vg}.

One way to avoid this issue, and I would argue the best, is to test these regions using a separate dataset, which completely avoids the issue of statistical 'double-dipping'. Of course, this requires that such a dataset is available or that resources exist to create it, which is frustratingly rare.

If the sample size is large enough, then permutation testing may also be appropriate. For example, \citet{Hansen:2013eo} permute the group labels of their samples and re-ran the analysis to determine for each of the observed DMRs "how often we see another block of similar length and effect size anywhere in the genome and in any of the permutations". The chief limitation of the permutation strategy is the restricted number of permutations that are possible from small sample sizes, along with the often substantial time and computational resources it takes to analyse the data for each permutation[^hansen_permutations].

[^hansen_permutations]: For example, \citet{Hansen:2013eo} only performed nine permutations to estimate significance.

Related to the method of creating DMRs by forming clusters of DMCs is that of "bump-hunting". Initially developed for application to methylation microarray data \citep{Jaffe:2012gx}, and now available for broader use in the R/Bioconductor package `bumphunter` ([http://bioconductor.org/packages/bumphunter/](http://bioconductor.org/packages/bumphunter/)), bump-hunting may be used to identify DMRs. The idea is as follows. Firstly, each each CpG is tested for differential methylation. The resulting test statistic is then considered as a function of the position in the genome[^smoothing] and processed with an algorithm to identify "bumps" in the signal. Bumps are defined as contiguous regions of the genome where the signal is above some threshold. The algorithm may include an error term to account for the spatial correlation of the signal and the significance of these peaks may be assessed using a permutation strategy.

[^smoothing]: The test statistic may be smoothed to reduce variation at the expense of increasing bias.

Another alternative for combining individual loci into data-driven DMRs uses the locus-specific P-values rather than the locus-specific test statistics. These methods can be thought of extensions to Fisher's method for combining P-values \citep{Fisher:1936vv}, that attempt to account for the correlation of tests at nearby methylation loci. `comb-p` \citep{Pedersen:2012vl} uses the Stouffer-Liptak-Kechris \citep{Stouffer:1949ua, Kechris:2010fw, Zaykin:2011jq} correction for spatially correlated P-values. `methylKit` \citep{Akalin:2012cm} uses `SLIM` \citep{Wang:2011cw} to do a similar correction.

Finally, there are a class of methods that turn the problem of identifying data-driven DMRs on its head by constructing the regions without first testing the individual loci for differential methylation. Then, only once these regions are defined, these methods test for differential methylation. This is different to using _a priori_ regions, since the regions are still data-defined, but not with respect to differential methylation. The only example of such a method that I am aware of is `Aclust` \citep{Sofer:2013bk}. `Aclust` first clusters CpGs into candidate regions by performing agglomerative nested clustering of the between-sample co-methylation. Briefly, this is the correlation of methylation levels at two loci across the samples[^between_sample_co-methylation]. These clusters are then tested for differential methylation using generalised estimating equations.

Regardless of the statistical method used to identify differential methylation, it remains important to validate these differences. This validation should ideally be performed in a new dataset and perhaps using a different assay in order to mitigate potential biases.

[^between_sample_co-methylation]: See Chapter \ref{chap:co-methylation_review} for further details of between-sample co-methylation.

\subsection{Differentially variable methlyation}\label{sec:variable_methylation}

It has been hypothesised that increased variability in DNA methylation indicates an epigentic _plasticity_ that may be highly relevant to common diseases, in particular, cancer \citep{Feinberg:2010dy}. Differential variability is distinct from differential methylation. Whereas the analysis of differential methylation is based on statistical tests of differences in means, the analysis of differential variability is based on statistical tests of differences in variances. Analogously, we define variably methylated cytosines (VMCs) and variably methylated regions (VMRs). To emphasise, a locus (resp. region) may be a DMC (resp. DMR) while not a VMC (resp. VMR) and _vice versa_.

\citet{Jaffe:2011hy} first developed formal statistical tests for differential variability of methylation for both the one-group and two-group experiments. These methods were developed for use with data from the CHARM array (see \ref{sec:enzyme_digestion_assays}). In a one-group experiment, a variably methylated region is one that has increased variability compared to 'similar' regions elsewhere in the genome. In a two-group experiment, a differentially variable locus is one where the variation in one group is significantly larger than that in the other group.

Statistical tests of variances are well known to be more difficult than tests of means and require larger sample sizes. A more subtle difficulty is in dealing with outliers. An outlier in one group will greatly increase the variation in that group, but this does not necessarily mean that the locus is differentially variably methylated. It might, for example, be due to an error in the assay. It is not difficult to envisage an example where the two groups in fact have very similar variability once the outlier is excluded.

Tests of differential variability that are based on the F-test \citep[e.g.,][]{Hansen:2011gu} or Bartlett's test \citep[e.g.,][]{Teschendorff:2012hea} will be susceptible to calling loci with such outliers as being differentially variable. By contrast, `DiffVar` \citep{Phipson:2014ji} uses Levene's test \citep{Olkin:1960uu} to test for differential variability since it is robust to outliers.

\subsection{Epigenome segmentation}\label{sec:epigenome_segmentation}

Methylation data in the form of the vectors of $\mathbf{m}$ and $\mathbf{u}$  may also be used by methods to segment the genome or epigenome into regulatory regions \citep{Stadler:2011kt}. One type of region that has received particular attention are so-called _partially methylated domains_ (PMDs). Partially methylated domains are long stretches of the genome where the average methylation level, $B_{i}$, is away from the extremes of $0$ and $1$, typically in the range $0.2$ to $0.7$.

PMDs were first identified in the _IMR90_ methylome by \citet{Lister:2009hy}. Using a simple sliding window algorithm, \citeauthor{Lister:2009hy} found that approximately $40\%$ of every autosome was a PMD and that the average length of these PMDs was a large 153 kb. They also showed that these PMDs were not simply due to a methylated subpopulation and an unmethylated subpopulation of cells in the sample. This did this by showing that individual reads mapped to these PMDs contained both methylated and unmethylated bases.

A subsequent study found that PMDs are a common feature of somatic cell lines and that they comprise $> 30\%$ of the genome \citep{Lister:2011kg}. Perhaps even more intriguingly, across four somatic cell lines profiled with whole-genome bisulfite-sequencing, \citeauthor{Lister:2011kg} found a large amount of these genomes ($664$ Mb) comprised shared PMDs.

PMDs have also been identified within tumour methylomes \citep{Berman:2012ga, Hansen:2011gu}. \citet{Hansen:2011gu} found that these PMDs overlap with other important genomic features called large organized chromatin lysine modifications (_LOCKs_) and lamina associated domains (_LADs_). However, PMDs are conspicuous by their absence in pluripotent cell lines, including both embryonic stem cells and induced pluripotent stem cells \citep{Lister:2011kg}. Their absence in the induced pluripotent cell lines may reflect the fact that the methylome is 'reset' upon induction of pluripotency \citep{Lister:2011kg, Stricker:2013kl}.

Recently, more sophisticated methods have been proposed to identify these PMDs. `methylSeekR` \citep{Burger:2013kq} is one such method. It uses a hidden Markov model of the $\beta$-values, combined with other filters, to segment the genome into unmethylated, lowly methylated and partially methylated regions.

\section{Methods based on m-tuples (m $> 2$)}\label{sec:downstream_analyses_of_m-tuples}

This section reviews the different types of questions that can be addressed by expanding our analysis to use methylation patterns at m-tuples (m $> 2$) rather than just 1-tuples. This extra information is only available from sequencing-based assays. We also review existing software that implement some of these methods.

\subsection{Methylation entropy}\label{sec:methylation_entropy}

The natural interpretation of methylation entropy is a measure of 'disorder'. It has been used to quantify how heterogeneous DNA methylation is at a locus \citep[e.g., ][]{Xie:2011cy, He:2013cj}[^other_definitions]. These methylation entropies can be analysed to identify heterogeneous regions of the genome or perhaps tested for an association with a phenotype.

[^other_definitions]: This is closely related to the idea of identifying epialleles, for which methylation entropy has also played a role \citep{Li:2014ei} and which I discuss in Section \ref{sec:epialleles}. Methylation entropy has also been used to identify differential methylation, however, I do not discuss this further since it uses a different definition that is not based on analysing methylation patterns at m-tuples \citep{Zhang:2011dp, Su:2012hl}.

On the one hand, if we only observe a single unique methylation pattern, then the m-tuple has the minimum methylation entropy of zero. On the other hand, if we observe all possible $2^{m}$ methylation patterns at equal frequency, then the m-tuple has the maximum methylation entropy (typically normalised to one). Depending on the frequency of the observed methylation patterns patterns, we obtain intermediate values of the methylation entropy.

\subsection{Allele-specific methylation}\label{sec:asm}

In a diploid cell, allele-specific methylation occurs when only one of the parental chromosomes is methylated at a particular locus, where the locus may be an individual cytosine or a broader region such as a gene promoter. A particularly interesting form of allele specific methylation occurs at imprinted genes, where one copy of the gene is active in a parent-specific manner. However, it is now apparent that allele-specific methylation is far more prevalent than at just these imprinted regions \citep{Tycko:2010hc, Shoemaker:2010jz}.

The obvious method to detect allele-specific methylation from bisulfite-sequencing requires reads that contain a heterozygous genetic variant, such as a single nucleotide polymorphism, along with at least one methylation locus. The heterozygous variant allows these reads to be separated by the observed allele[^phase], which can then be used to test for allele-specific methylation. For example, \citet{Shoemaker:2010jz} construct a $2 \times 2$ contingency table, like that shown in Table \ref{tab:asm}, and test for an association between the allele and the methylation state using Fisher's exact test \citep{Fisher:1922bx}.

[^phase]: This does not give parent-specificity unless the phase of the genotype is also known.

\begin{table}[h]
\centering
\caption[Allele-specific methylation]{$2 \times 2$ table used to test for allele-specific methylation. $m^{1}$ is the number of reads with the first allele and that are also methylated at the methylation locus, $u^{1}$ is the number of reads with the first allele and that are also unmethylated at the methylation locus, etc.}
\label{tab:asm}
\begin{tabular}{@{}lll@{}}
\toprule
& Allele 1 & Allele 2 \\ \midrule
$m$ &  $m^{1}$        &  $m^{2}$       \\
$u$ &  $u^{1}$        &  $u^{2}$       \\ \bottomrule
\end{tabular}
\end{table}

While straightforward, this approach is also obviously limited to the small number of methylation loci that are nearby to a heterozygous genetic variant. \citet{Fang:2012ci} and \citet{Peng:2012dh} published methods to detect allele-specfic methylation that do not require heterozygous genetic variants nearby to the methylation locus of interest. These methods rely on the probabilistic assignment of reads to alleles (which are treated as missing data). Unfortunately, there is no publicly available software implementing the method proposed by \citet{Peng:2012dh} and so I do not discuss it further.

\citet{Fang:2012ci} use reads containing multiple methylation loci and looks for regions of the genome where there are two distinct methylation patterns at the read-level that occur at roughly equal proportions, indicating one pattern comes from one allele and the other pattern from the other allele. The likelihood of allele-specific methylation is computed using an expectation-maximisation algorithm, which assigns reads to one of the two possible alleles. Neighbouring regions displaying allele-specific methylation are then joined together. While not mentioned in the paper, the proposed method is now available in the `MethPipe` software ([http://smithlabresearch.org/software/methpipe/](http://smithlabresearch.org/software/methpipe/)).

\subsection{Epialleles}\label{sec:epialleles}

A DNA sequence may have multiple epigenetic states. For example, the cytosine in the sequence _TCGA_ may be methylated or unmethylated; each of the methylated and unmethylated versions of that sequence is an _epiallele_. \citet{Rakyan:2002wz} define an _epiallele_ as "an allele that can stably exist in more than one epigenetic state, resulting in different phenotypes". The latter requirement, while obviously more interesting than the alternative, may be unduly restrictive. After all, we refer to alternative forms of a genetic sequence as _alleles_ regardless of whether we know of a phenotypic consequence of the variant.

Most of the examples of epialleles with a phenotypic consequence come from the plant kingdom and, even there, the number of such epialleles is small: a review from 2012 put the number at "about a dozen" \citep{Weigel:2012fj}. In mammals, the study of epialleles has focused on identifying _metastable_ epialleles, which are epialleles that are mitotically heritable \citep{Rakyan:2002wz}. The poster child for the potential importance of epialleles in mammals is the Agouti viable yellow ($A^{vy}$) allele \citep{Morgan:1999ds}. Genetically identical mice with different versions of the $A^{vy}$ allele are phenotypically distinct. Those mice with an unmethylated version of the allele have a yellow coat, are obese, diabetic, and have an increased susceptibility to tumours; those mice with a methylated version of the allele have a _pseudoagouti_[^pseudoagouti_vs_agouti] (brown) coat and none of the associated health defects.

[^pseudoagouti_vs_agouti]: These mice are properly described as _pseudoagouti_ rather than agouti. They are heterozygous for the wildtype agouti allele ($A^{vy}/a$) but are phenotypically indistinguishable from true agouti mice, which are homozygous for the wildtype gene ($a/a$).

In humans, there have been several interesting studies using putative epialleles to infer the clonality and evolution of cancer \citep{Siegmund:2009kk, Li:2014ei}, as well as to study the evolution of methylation dynamics and the rate of epipolymorphism of various loci in an immortalised cell line \citep{Landan:2012kp}.

Regardless of where you draw the line as to what constitutes an epiallele, it has become clear in the analysis of bisulfite-sequencing data that the occurrence of multiple methylation patterns at an m-tuple is the norm rather than the exception.

Restricting our attention to CpG methylation, a sequence with $m$ CpGs has $2^{m}$ potential epialleles. In other words, an epiallele is just a methylation pattern at an m-tuple, with the additional constraint that the underlying DNA sequence also be identical. An epiallele may also be described as an _epimutation_ if it is different from the 'normal' methylation state.

The _rate of epipolymorphism_ of a locus is defined as the probability that two epialleles randomly sampled from the locus are different from one another \citep{Landan:2012kp}[^epipolymorphism]. \citeauthor{Landan:2012kp} define the rate of epipolymorphism of an m-tuple as $1 - \sum_{p = 1}^{p = 2^{m}} f_{p}^{2}$, where $f_{p}$ is the estimated frequency of the $p^{th}$ methylation pattern, i.e. the number of times the $p^{th}$ pattern is observed divided by the total number of reads mapped to that m-tuple[^sampling_with_replacement]. Unlike genetic polymorphisms, where the population is typically a set of chromosomes from multiple individuals, the population of epipolymorphisms is often within an individual, even within a tissue within an individual.

[^epipolymorphism]: \citet{Landan:2012kp} actually call this the "epipolymorphism" of the locus rather than the "rate of epipolymorphism" of the locus. However, I think this is better described as a rate since it refers to the frequency at which we observe epialleles/epipolymorphisms.

[^sampling_with_replacement]: Strictly speaking, this is in fact an estimate of the rate of epipolymorphism of the locus under a model that assumes sampling with replacement or, equivalently, an infinite population size. While neither assumption is true, the correction for sampling without replacement from a finite population will not substantially affect the results provided that the sequencing depth is high.

The obvious challenge in estimating the frequency of an epiallele is in distinguishing a 'real' epiallele from a spurious one (perhaps caused by incomplete bisulfite-conversion) sequencing error or mapping error. Another difficulty, perhaps unavoidable with current technology, is the effect of PCR amplification bias, which will bias estimates of the relative abundance of each epiallele.

Of the downstream analyses based on methylation patterns at m-tuples, the study of epialleles has received the most attention with respect to methods and software development.

`methclone` \citep{Li:2014ei} is a method to estimate the frequency of epialleles at m-tuples (the rate of epipolymorphism) and to identify "shifts" in these distributions between a pair of samples. `methclone` is based on computing and comparing two forms of methylation entropy, the "foreground" and "background". The foreground combinatorial entropy, $S$, is based on the observed frequency of epialleles in the two samples. The background combinatorial entropy, $\tilde{S}$, is the expected frequency of epialleles in the two samples if "all patterns of epialleles are uniformly mixed between the two [samples]". The difference in these combinatorial entropies, $\Delta S = S - \tilde{S}$, a kind of observed-to-expected log-ratio, is used to identify shifts in the epiallele distribution between a pair of samples. A $\Delta S = 0$ corresponds to no change and a $\Delta S = -144$ corresponds to maximal difference in entropy. It isn't clear whether the range of $\Delta S$ depends on the size of the m-tuples nor is it clear how to choose the threshold at which to declare a significant shift in the distribution of epialleles.

`methclone` uses the observed frequencies of methylation patterns as being unbiased estimates of the true epiallele frequencies and does not attempt to account for potential sources of bias. In contrast, `MPFE` (\url{http://bioconductor.org/packages/MPFE}, \url{http://f1000.com/posters/browse/summary/1097258}), an R/Bioconductor package for "[estimating] the distribution of methylation patterns [i.e. epialleles]" at m-tuples, uses a probabilistic model to account for some of these biases.

`MPFE` is designed to estimate the frequency of epialleles by maximising a multinomial likelihood that includes error terms for both incomplete bisulfite-conversion and sequencing error. The maximisation of this likelihood is computatationally demanding, as evidenced by the need for a "fast" algorithm that approximates the likelihood. `MPFE` is designed for amplicon bisulfite-sequencing and may not scale to whole-genome data. The input is a file containing the number of times each methylation pattern was observed at that m-tuple. Unfortunately, `MPFE` does not provide a way to create this file.

Methods designed to detect allele-specific methylation, specifically those that are based on the observed methylation patterns \citep[e.g.,][]{Fang:2012ci, Peng:2012dh}, might also be adapted to identify epialleles and their associated frequencies. It is worth emphasising that since all of the methods described in this section are based entirely on the observed methylation patterns, none of these actually check that the underlying DNA sequencing is identical, which, strictly speaking, is a requirement for the m-tuple to be an epipolymorphic locus.

\subsection{Software for analysing methylation patterns at m-tuples}\label{sec:methylation_pattern_software}

Generally speaking, there are fewer software options for analysing methylation patterns at m-tuples (m $> 2$) than there are for analysing methylation patterns at 1-tuples. Furthermore, the available options are often difficult to extend since they are typically developed for a specific task and not for general computations with methylation patterns at m-tuples.

I have also experienced considerable difficulty in applying some of these methods owing to poor software implementations. To give two examples, `DMEAS` \citep{He:2013cj} is only available as a Windows binary or as a Perl script that itself is only available as a PDF file, and I have been unable to install `methclone` due to compilation errors.

`MethPipe` is perhaps the best documented and potentially extensible software for analysing methylation patterns at m-tuples. `MethPipe` is mostly written in \CC \ and is designed as a suite of tools for a complete 'pipeline' analysis of bisulfite-sequencing data. As such, it does not feature tools that are particularly amenable to interactive or exploratory analyses. In fact, I am unaware of any software that allows easy exploratory analyses of methylation patterns at m-tuples, which in part motivated the development of `MethylationTuples`.

\section{\texttt{MethylationTuples}}\label{sec:MethylationTuples}

In order to facilitate the development of downstream analysis methods based on methylation patterns at m-tuples, I saw the need for two pieces of software:

1. Software for extracting methylation patterns at m-tuples,
2. Software for manipulating, analysing and visualising these methylation patterns.

I have made significant progress towards the first goal with `methtuple` (see Section \ref{sec:methtuple}) and now introduce `MethylationTuples` ([https://github.com/PeteHaitch/MethylationTuples](https://github.com/PeteHaitch/MethylationTuples)) to address the second missing link.

\subsection{Design}

`MethylationTuples` is an R package for managing, analysing and visualising methylation patterns at m-tuples. It is released under an Artistic-2.0 license, consistent with core Bioconductor packages. I chose to write this software in R because it is a very popular language for data analysis, particularly in bioinformatics, and facilitates both batch and interactive usage. R is also my computational mother tongue and an R package is a convenient unit for sharing reusable code. To improve the performance of key functionality, parts of `MethylationTuples` are written in \CC, making use of the `Rcpp` package \citep{Eddelbuettel:2011to,Eddelbuettel:2013if}.

While initially developed to support my research into co-methylation (Chapter \ref{chap:co-methylation}), the data structures developed in `MethylationTuples` are well-suited to other analyses based on methylation patterns of m-tuples such as methylation entropy, allele-specific methylation and the identification of epialleles. Of course, `MethylationTuples` can also be used to develop methods based on 1-tuples, such as identifying differential methylation, since 1-tuples are just a particular type of m-tuple.

`MethylationTuples` is written to work within the Bioconductor project \citep{Gentleman:2004ju}[^bioc]. Bioconductor makes extensive use of R's S4 object system and encourages developers to re-use existing Bioconductor infrastructure. From a developer's perspective, this avoids the need to re-invent the wheel when tackling common tasks. And from the user's perspective, it helps avoid multiple versions of the wheel, each that might otherwise act slightly differently and that may not be as well-tested.

[^bioc]: `MethylationTuples` has not yet been submitted to Bioconductor but its development is being published to \url{https://github.com/PeteHaitch/MethylationTuples}).

Bioconductor already has excellent support for working with data defined on genomic ranges via the `IRanges` and `GenomicRanges` packages \citep{Lawrence:2013hi, Lawrence:2014gy}. Genomic tuples, however, such as the co-ordinates of an m-tuple, do not naturally fit into this framework[^tuples_vs_ranges]. Therefore, I first wrote a Bioconductor package for working with genomic tuples, rather unimaginatively called `GenomicTuples`, first released as part of Bioconductor version 3.0 (\url{http://bioconductor.org/packages/GenomicTuples}). In fact, `GenomicTuples` is heavily based on the `GenomicRanges` package, with modifications for tuple-specific operations. This makes it easy to use for users already familiar with the `GenomicRanges` package. For example, there is a tuple-specific method for the `findOverlaps` generic function to identify genomic tuples with equal co-ordinates (i.e. \texttt{type = `equal'}). Since the classes in `GenomicTuples` extend those defined in `GenomicRanges`, these have excellent interoperability with existing Bioconductor infrastructure.

[^tuples_vs_ranges]: The difference between a genomic range and a genomic tuple  can be thought of as the difference between an interval and a set. Namely, an interval includes the co-ordinates in between the start and end whereas a set only includes those co-ordinates listed in the set. For example, the genomic interval `chr3:+:[10, 12]` includes the co-ordinates `chr3:10`, `chr3:11` and `chr3:12` on the forward strand, whereas the genomic 2-tuple `chr3:+:{10, 12}` only includes the co-ordinates `chr3:10` and `chr3:12` on the forward strand.

In the `MethylationTuples` package I define the `MethPat` class to store the genomic co-ordinates of m-tuples and the associated counts of each methylation pattern. A `MethPat` object is as a matrix-like object, where rows represent m-tuples and columns represent samples. The `MethPat` class extends the `GenomicRanges::SummarizedExperiment`[^namespace] class but makes use of classes defined in the `GenomicTuples` package to store the genomic co-ordinates of the m-tuples. Currently, it is a requirement that all m-tuples in a `MethPat` object have the same size (i.e. same $\text{m}$).

[^namespace]: This uses the NAMESPACE notation of R: `GenomicRanges::SummarizedExperiment` can be read as "the `SummarizedExperiment` class is part of the `GenomicRanges` package".

Figure \ref{fig:MethPat} is a schematic of a `MethPat` object storing methylation patterns at 3-tuples for $n$ samples. The similarities to the output format of `methtuple` are clear (see Figure \ref{fig:3-tuples}), with the added advantage that a single `MethPat` object can contain data from multiple samples.

\begin{figure}[h]
\includegraphics[width=\textwidth]{../figures/MethPat.pdf}
\caption[Schematic of \texttt{MethPat} class]{Schematic of the \texttt{MethPat} class, shown here for 3-tuples. Each row represents a 3-tuple to which the genomic co-ordinates of the tuples (green box) and the counts of the methylation patterns (grey box) are aligned. The counts of each methylation pattern ($MMM, MMU, \ldots, UUU$) are stored as separate matrices where the columns represent samples ($S_{1}, \ldots, S_{n}$). Some samples may not have any sequencing coverage for a particular m-tuple, in which case the corresponding frequencies are recorded as \texttt{NA}.}
\label{fig:MethPat}
\end{figure}

[^methtuple_output]: See Section \ref{sec:methtuple_methods} for example of the `methtuple` output format.

\subsection{Methods}

A `MethPat` object can be constructed directly using the `MethPat()` constructor function or from the output files of `methtuple` via the `readMethtuple()` function.

The `MethPat` object provides fast subsetting by rows (m-tuples) and columns (samples) via the "`[`" method. It also benefits from fast subsetting based on overlaps of m-tuples with genomic features via the `findOverlaps()`-based methods. Several other useful utility functions for working with `MethPat` objects include:

- `collapseStrand()`: Collapse strand-specific data by aggregating the counts. Only applicable to CpG methylation loci.
- `combine()`: Combine multiple `MethPat` objects into one.
- `filterOutVariants()`: Remove m-tuples that contain a known variant. Variants must be provided as a `VCF` file.
- `findMTuples()`: Find m-tuples of a given size in a reference genome.
- `getCoverage()`: Compute the sequencing coverage of each m-tuples in each sample.
- `IPD()`: Compute the IPD vector for each m-tuple.
- `methLevel()`: Compute $\beta$-values or $\mathcal{M}$-values. Only applicable to 1-tuples.
- `tuples()`: Extract the $pos_{1}, \ldots, pos_{m}$ of the m-tuples.

These are in addition to the many useful methods inherited from the \linebreak `GenomicRanges::SummarizedExperiment` class.

With the `MethPat` class, its associated methods and other utility functions, the `MethylationTuples` package provides a toolbox for manipulating methylation patterns at m-tuples. Aside from providing the necessary infrastructure to analyse methylation patterns at m-tuples, `MethylationTuples` currently includes specific methods to analyse and visualise co-methylation (Chapter \ref{chap:co-methylation}) with the `cometh()` and `methLevelCor()` methods. I also plan to add methods for estimating epialleles and epipolymorphism. It is my hope that `MethylationTuples` will provide a useful foundation on which others can implement their own methods for analysing methylation patterns at m-tuples.

\subsection{Compatability with other Bioconductor packages}

Since `MethylationTuples` is based on core Bioconductor functionality, it is highly compatible with existing Bioconductor packages. In particular, `MethPat` objects containing 1-tuples are readily coerced for use with differential methylation calling packages, e.g., `bsseq` and `BiSeq`, or to identify partially methylated domains with `MethylSeekR`. I also make extensive use of `MethylationTuples` in my `methsim` software (Chapter \ref{chap:methsim})

\subsection{Computational challenges and future directions}

The challenges of working with large datasets in R are well-known. These are in large part due to R being designed as an 'in-memory' application and its implementation of 'copy-on-modify' semantics \citep{wickham2014advanced}. More generally, with large datasets, there is often a trade-off to be made between storage efficiency and algorithm simplicity; a more efficient way of storing the data may be less convenient to work with and _vice versa_.

I have used the `MethylationTuples` package to analyse various sized m-tuples from datasets containing up to 17 whole-genome bisulfite-sequencing samples (the _Lister_ data). I have found the `MethPat` class to be a very convenient representation of the data, however, it has also raised challenges that will apply for larger datasets.

One such challenge is the size of a `MethPat` object in memory. The `MethPat` class currently favours a simpler implementation at the expense of storage efficiency. The main inefficiency with the `MethPat` class is that the matrices storing the counts of each methylation pattern grow increasingly sparse as the size of the tuples increases.

Shown in Table \ref{tab:methpat_sparsity} is the size of the `MethPat` objects in memory for the _EPISCOPE_ whole-genome bisulfite-sequencing data with various sized m-tuples. We see that as the size of the m-tuples increases, the data become sparser: most counts are 0 (meaning that particular methylation pattern was not observed in that particular sample) or `NA` (meaning that that m-tuple was not observed in that particular sample). However, for values of $m < 5$, and particularly for 'dense' data, such as RRBS, this is far less of an issue.

\begin{table}[h]
\centering
\caption[Size of \texttt{MethPat} objects for the \emph{EPISCOPE} data]{Size of \texttt{MethPat} objects for the \emph{EPISCOPE} data ($N_{samples} = 12$). All m-tuples are stranded. The `size' of the \texttt{MethPat} object, reported in gigabytes (GB), is computed using the \texttt{pryr::object\_size()} function (\url{http://cran.r-project.org/web/packages/pryr/index.html}). The `number of rows' corresponds to the number of m-tuples in the object. The `number of assays' is $2^{\text{m}}$, where m is the size of the m-tuples. The final column is a measure of how sparse the data are: a $0$ value means that particular methylation pattern was not observed in that particular sample and an \texttt{NA} value means that that m-tuple was not observed in that particular sample.}
\label{tab:methpat_sparsity}
\begin{tabulary}{\textwidth}{LRRRR}
\toprule
& Size (GB) & Number of rows & Number of assays & Percentage of $0$ and \texttt{NA} values \\ \midrule
1-tuples                                 & $5.9$                        & $56,348,522$  & $2$              & $28\%$                                     \\
2-tuples                                 & $20.1$                       & $100,586,237$ & $4$              & $80\%$                                     \\
2-tuples (\texttt{{-}{-}all-combinations}) & $60.0$                          & $299,814,999$  & $4$              & $78\%$                                     \\
3-tuples                                 & $43.3$                       & $109,376,348$ & $8$              & $93\%$                                     \\
4-tuples                                 & $80.5$                       & $102,625,758$ & $16$             & $97\%$                                       \\ \bottomrule
\end{tabulary}
\end{table}

It will be possible to improve the storage efficiency by using a different approach to the internal storage of the data. For example, it may be possible to use sparse matrices to store the counts or to create an index so that counts can be re-ordered and stored as run-length encodings, a very space-efficient storage scheme.

In the short term, my aim for `MethylationTuples` is to release a version to Bioconductor with the core infrastructure for manipulating data of methylation patterns at m-tuples. In the longer term, I would like to extend the set of downstream analyses of m-tuples that are available in the package and to help users extend the package to add their own methods.

\section{Summary}

Most methods for downstream analyses of bisulfite-sequencing data have focused on the problem of identifying differential methylation using methylation calls at 1-tuples. However, there is a growing interest in questions related to the heterogeneity of DNA methylation and these might be better addressed by analyses based on methylation patterns at m-tuples.

A barrier to these type of analyses has been a lack of software for extracting and manipulating these data. It is my hope that the `methtuple` and `MethylationTuples` software will prove useful in facilitating the development of methods for these new types of downstream analyses.
