---
title: "Appendix"
author: "Peter Hickey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: ../latex/header.tex
    keep_tex: no
  html_document:
    keep_md: yes
bibliography: ../latex/phd_thesis.bib
---

## CpGs are underrepresented in the human genome (hg19)

Firstly, the frequency of each nucleotide is computed. Secondly, the expected frequency of each dinucleotide is computed under the _independence model_. Under the independence model, the frequency of each dinucleotide is simply the product of the respective observed nucleotide frequencies. Finally, these expected frequencies are compared to the observed values from the respective reference genomes.

I only use the autosomes, sex chromosomes and mitochondrial chromosome in all analyses, that is, I do not consider the "random", "unplaced" and "alternate haplotype" contigs in the reference genomes.

All results are computed at the chromosome-level as well as being summarised genome-wide.

### Compute the nucleotide and dinucleotide frequencies

```{r, cache = TRUE}
library(BSgenome.Hsapiens.UCSC.hg19)
library(knitr)
# Nucleotide frequencies
nf <- bsapply(new("BSParams", X = Hsapiens, FUN = letterFrequency,
            exclude = c("rand", "Un", "hap"), simplify = TRUE),
            letters = c("A", "C", "G", "T"))
# Pretty print the results
kable(data.frame(percentage = round(100 * rowSums(nf) /
                                      sum(as.numeric(nf)), 1)))

# GC-percentage
round(100 * sum(nf[c("C", "G"), ]) / sum(as.numeric(nf)), 1)

# Dinucleotide frequencies
df <- bsapply(new("BSParams", X = Hsapiens, FUN = dinucleotideFrequency,
            exclude = c("rand", "Un", "hap"), simplify = TRUE))
# Pretty print the results
kable(data.frame(percentage = round(100 * rowSums(df) /
                                      sum(as.numeric(df)), 1)))

# CpG percentage
round(100 * rowSums(df) / sum(as.numeric(df)), 1)["CG"]
```

### Plot the observed:expected ratio for each dinucleotide

```{r dinucleotide_distribution, fig.lp = "fig:dinuclotide_distribution", dev = "pdf"}
library(ggplot2)
thesis_theme <- theme_classic(base_size = 12)
thesis_theme <- theme_bw(base_size = 12)
edf <- nf %*% t(nf) / (sum(nf %*% t(nf))) * 100
x <- data.frame(Dinucleotide = names(rowSums(df)),
                Observed = as.vector(100 * rowSums(df) / sum(as.numeric(df))),
                Expected = as.vector(edf))
ggplot(x, aes(x = Dinucleotide, y = Observed / Expected)) +
  geom_point(size = 5) + coord_cartesian(ylim = c(0, 1.5)) +
  ggtitle("CpGs are underrepresented in human reference genome (hg19)") +
  thesis_theme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_hline(yintercept = 1, linetype = 2)
```

### Frequency of CpGs on each chromosome in the human reference genome (hg19)

Chromosome 19 has the highest CpG density of the autosomes in the human reference genome (hg19):
```{r cpg_frequency}
sort(df['CG', ] / colSums(df) * 100, decreasing = TRUE)
```

## Distances between CpGs in the human reference genome (hg19)

I extract the co-ordinates of all CpGs in the human reference genome (hg19) and compute the intra-pair distances (IPD) between adjacent CpGs. I then plot the empirical cumulative distribution function of IPD. These are compared to the distances we would expect if CpGs were uniformly distributed across the genome.

I only use the autosomes, sex chromosomes and mitochondrial chromosome in all analyses, that is, I do not consider the "random", "unplaced" and "alternate haplotype" contigs in the reference genomes.

```{r cpg_ipds, cache = TRUE}
library(BSgenome.Hsapiens.UCSC.hg19)
set.seed(666)

# Observed IPDs
cpgs <- bsapply(new("BSParams", X = Hsapiens, FUN = matchPattern,
                    exclude = c("rand", "Un", "hap"), simplify = TRUE),
                pattern = "CG")
d <- unlist(lapply(cpgs, start), use.names = FALSE)
ipd <- diff(d)
# Drop negative distances, which correspond to CpGs on different chromosomes
ipd <- ipd[ipd > 0]

# Expected IPDs if CpGs were uniformly distributed on genome
d_sim <- bsapply(new("BSParams", X = Hsapiens, FUN = function(x) {
  cpg_freq <- countPattern("CG", x)
  sort(sample(x = length(x), size = cpg_freq, replace = FALSE))
}, exclude = c("rand", "Un", "hap"), simplify = TRUE))
ipd_sim <- diff(unlist(d_sim, use.names = FALSE))
# Drop negative distances, which correspond to CpGs on different chromosomes
ipd_sim <- ipd_sim[ipd_sim > 0]

# Drop negative values, which are due to CpGs being on different chromosomes
ipd_df <- data.frame(IPD = c(ipd, ipd_sim),
                  Source = c(rep("Observed", length(ipd)),
                             rep("Expected", length(ipd_sim))))
```

### Empirical cumulative distribution plot

```{r cpg_ipds_cdf, dev = "pdf"}
library(ggplot2)
thesis_theme <- theme_classic(base_size = 12)
thesis_theme <- theme_bw(base_size = 12)

ggplot(aes(x = IPD, colour = Source), data = ipd_df) + stat_ecdf() + thesis_theme +
  coord_cartesian(xlim = c(0, 1000)) +
  xlab("Distance between CpGs (bp)\n(Axis truncated at 1000)") +
  ggtitle("Human reference genome (hg19)")
```

### Frequency polygon

```{r cpg_ipds_hist, dev = "pdf"}
library(ggplot2)
library(scales)
thesis_theme <- theme_classic(base_size = 12)
thesis_theme <- theme_bw(base_size = 12)

ipd_table <- table(ipd)
ipd_sim_table <- table(ipd_sim)
ipd_table_df <- data.frame(IPD = c(as.numeric(names(ipd_table)),
                                   as.numeric(names(ipd_sim_table))),
                           Count = c(ipd_table, ipd_sim_table),
                           Source = c(rep("Observed", length(ipd_table)),
                                      rep("Expected", length(ipd_sim_table))))

ggplot(aes(x = IPD, y = Count),
       data = subset(ipd_table_df, Source == "Observed")) +
  geom_line() + coord_cartesian(xlim = c(0, 300)) +
  xlab("Distance between CpGs (bp)\n (Axis truncated at 300)") +
  ggtitle("Human reference genome (hg19)") +
  scale_y_continuous(labels = comma)
```

## Equivalence of tests to identify DMCs in a one-group experiment

The computational equivalence of using Pearson's $\chi^{2}$ test, the deviance of a log-linear model and the deviance of a logistic regression are shown in the following R code:

```{r}
# The data
x <- cbind(M = c(38, 79, 59, 69, 44), U = c(1, 2, 1, 2, 46))
names(dimnames(x)) <- c("sample", "meth_state")
x

# Using Pearson's chi-square test
chisq.test(x)

# Fitting a log-linear model to perform iterative proportional fitting to the
# contingency table.
loglin(x, margin = list("sample", "meth_state"))
# An alternative formulation using loglm(), a convenient wrapper of loglin(),
# from the MASS package.
library(MASS)
loglm(formula =  ~ sample + meth_state, data = x)

# Fitting a generalised linear model with a binomial link using two different
# formulations
# (1) Using the array of frequencies
glm(x ~ 1, family = binomial)
# (2) Using relative frequencies (i.e., the beta-values) and weights (i.e.,
  # the sequencing coverage).
  glm(x[,1] / (x[, 1] + x[, 2]) ~ 1, family = binomial, weights = x[, 1] + x[, 2])
```

The saturated log-linear model can be written as $\log(F_{a, b}) = \lambda_{0} + \lambda_{a}^{meth_state} + \lambda_{b}^{sample} + \lambda_{a, b}^{meth_state,sample}$, where $F_{a, b}$ is the value of the $(a, b)$ element in the $n \times 2$ contingency table. The null hypothesis that the cytosine is not a DMC is then tested by testing for an association between `sample` and `meth_state`, i.e., whether the parameter $\lambda_{a, b}^{meth_state, sample}$ is significantly different from zero.

This log-linear model can be reformulated as a logistic regression by noting that the log-odds (logits) for each row are $\log(\frac{F_{a, 1}}{F_{a, 2}}) = \log(F_{a, 1}) - \log(F_{a, 2})$. Therefore,

\begin{align*}
\log(\frac{F_{a, 1}}{F_{a, 2}}) &= \lambda_{0} + \lambda_{a}^{meth_state} + \lambda_{1}^{sample} + \lambda_{a, 1} \\
&- (\lambda_{0} + \lambda_{a}^{meth_state} + \lambda_{2}^{sample} + \lambda_{a, 2}) \\
&= \underbrace{(\lambda_{1}^{sample} - \lambda_{2}^{sample})}_{\alpha} + \underbrace{(\lambda_{a, 1} - \lambda_{a, 2})}_{\gamma_{i}}
\end{align*}

The expression $\log(\frac{F_{a, 1}}{F_{a, 2}}) = \alpha + \gamma_{i}$ is a logistic regression model. We can test the null hypothesis that the cytosine is not a DMC by testing for a `sample`-effect on the log-odds, i.e., whether the parameter $\gamma_{i}$ is significantly different from zero.

Regardless of whether we use the log-linear model or the logistic model, to test the null hypothesis that the cytosine is not a DMC we can compute the deviance[^deviance] of the reduced model and compare it to a $\chi^{2}$ random variable with $(2 - 1) \times (n - 1)$ degrees of freedom. For the log-linear regression the reduced model is $\log(F_{a, b}) = \lambda_{0} + \lambda_{a}^{meth_state} + \lambda_{b}^{sample}$ and for the logistric regression the reduced model is $\log(\frac{F_{a, 1}}{F_{a, 2}}) = \alpha$.

[^deviance]: The deviance is the log-likelihood ratio statistic comparing the current model within a saturated model.

## The probability that two dependent Bernoulli random variables are identical

\cite{Lindqvist:1978fm} wrote a brief note on Bernoulli trials with dependence.
Building on earlier work by \cite{Klotz:1973if}, Lindqvist parameterises the
Bernoulli process $X_{1}, X_{2}, \ldots$ on $\{0, 1\}$ by the parameters
$p = Pr(X_{i} = 1)$ and $c = cor(X_{i - 1}, X_{i})$ and shows that the
transition matrix is given by

\begin{equation*}
\label{eq:transition_matrix_id}
\Pi =
 \begin{pmatrix}
  (1 - p) + cp & p (1 - c) \\
  (1 - p) (1 - c) & p + c (1 - p)
 \end{pmatrix}
\end{equation*}

provided that $max(1 - \frac{1}{p}, 1 - \frac{1}{1 - p}) \leq c \leq 1$.

From this we can compute the joint distribution,

\begin{equation*}
Pr(X_{1} = x_{1}, \ldots, X_{n} = x_{n}) = Pr(X_{1} = x_{1}) Pr(X_{2} = x_{2} | X_{2} = x_{2}) \cdots Pr(X_{n} = x_{n} | X_{n - 1} = x_{n - 1})
\end{equation*}

In particular, in the case $n = 2$ we can compute the probability that two
dependent but identically distributed Bernoulli random variables are equal.

To extend the above result to the probability that two dependent and
__non-identically__ distributed Bernoulli random variables are equal, simply
requires that we derive the appropriate transition matrix. Switching notation
to that used in Chapter \ref{chap:co-methylation_review}, let
$Z_{h, i} \eqd Bernoulli(p_{h})$ and $Z_{h', i'} \eqd Bernoulli(p_{h'})$. The
transition matrix,
$\Pi = \bigl(\begin{smallmatrix}
Pr(Z_{h', i'} = z_{h', i'} | Z_{h, i} = z_{h, i})
\end{smallmatrix} \bigr)$, is given by

\begin{equation*}
\label{eq:transition_matrix_nid}
\Pi =
 \begin{pmatrix}
  (1 - p_{h'}) + c p_{h} & p_{h'} - c p_{h} \\
  \big [ (1 - p_{h'}) + c p_{h} \big ] (1 - p_{h}) & \big [ p_{h'} + c (1 - p_{h}) \big ] p_{h}
 \end{pmatrix}
\end{equation*}

We can then compute the desired probability

\begin{align*}
Pr(Z_{h, i} = Z_{h', i'}) &= Pr(Z_{h, i} = 0, Z_{h', i'} = 0) + Pr(Z_{h, i} = 1, Z_{h', i'} = 1) \\
                  &= Pr(Z_{h', i'} = 0 | Z_{h, i} = 0) Pr(X_{0} = 0) +
                     Pr(Z_{h', i'} = 1 | Z_{h, i} = 1) Pr(X_{0} = 1) \\
                  &= \big [ (1 - p_{h'}) + c p_{h} \big ] (1 - p_{h}) +
                     \big [ p_{h'} + c ( 1 - p_{h}) \big ] p_{h} \\
                  &= (1 - p_{h}) (1 - p_{h'}) + c p_{h} \big [1 - p_{h}] +
                     p_{h} p_{h'} + c p_{h} (1 - p_{h}) \\
                  &= (1 - p_{h}) (1 - p_{h'}) + p_{h} p_{h'} + 2 c p_{h} (1 - p_{h})
\end{align*}

__TODO: What is the general restriction on $c$ when $p_{h, i} \neq p_{h', i'}$?__

## Analysis of \cite{Lacey:2013iy}

I want to estimate the number of CpGs used by \cite{Lacey:2013iy} to estimate the correlation of methylation levels. They used the chromosome 11 data from an RRBS experiment on a normal myotube cell line, MTCTL2. Unfortunately, the data are not publicly available. Instead, I use data from ENCODE of a skeletal muscle myotubes cell line that had RRBS performed in triplicate (HSMMtube).

Firstly, I download the data and unzip it:
```{r, cache = FALSE, message = FALSE}
library(R.utils)
library(data.table)
library(dplyr)
print(getwd())
```

```{r, cache = FALSE, message = FALSE}
dl_dir <- 'downloads/'
url <- 'http://hgdownload.cse.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeHaibMethylRrbs/'
files <- paste0('wgEncodeHaibMethylRrbsHsmmtubefshdDukeSitesRep',
                1:3, '.bed.gz')
dests <- paste0(dl_dir, files)
x <- mapply(function(f, d) {
  if (!file.exists(gsub(".gz", "", paste0(dl_dir, f)))) {
    download.file(url = paste0(url, f), d)
    gunzip(filename = d, overwrite = TRUE)
    }
  fread(gsub(pattern = '.gz', replacement = '', x = d), sep = '\t',
        verbose = FALSE)
  }, files, dests, SIMPLIFY = FALSE)
```

Then I count the number of CpGs on chromosome 11 in each sample:
```{r}
y <- lapply(x, function(xx) {
  xx <- tbl_dt(xx)
  xx %>%
    group_by(V1) %>%
    summarise(n())
})

rbind_all(y) %>% filter(V1 == 'chr11')
```

## Computing details

All computational work was performed on one of the Bioinformatics Division's HP Blade servers. These are shared-use, shared-memory machines. The basic specifications are shown in Table \ref{tab:unices}.

\begin{table}[h]
\centering
\begin{tabular}{@{}lllll@{}}
\toprule
Machine name & Processors                           & Cores per processor & Total number of cores & RAM    \\ \midrule
unix88       & $4\times$ Intel Xeon X7350 @ 2.93GHz & 4                   & 16                    & 128 GB \\
unix301      & $4\times$ AMD Opteron 8435 @ 2.6GHz  & 6                   & 24                    & 256 GB \\
unix302      & $4\times$ AMD Opteron 6174 @ 2.2GHz  & 12                  & 48                    & 512 GB \\
unix303      & $4\times$ AMD Opteron 6176 @ 2.3GHz  & 12                  & 48                    & 512 GB \\
unix305      & $4\times$ AMD Opteron 6276 @ 2.3GHz  & 16                  & 64                    &        \\ \bottomrule
\end{tabular}
\caption{Bioinformatics Division server specifications.}
\label{tab:unices}
\end{table}

## Software details

```{r}
devtools::session_info()
```

### TODOs

* Cite data source and publication
