---
title: "Statistical analysis of whole-genome bisulfite-sequencing data"
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: ../latex/header.tex
  html_document:
    keep_md: true
bibliography: ../latex/phd_thesis.bib
---

\chapter{Statistical analysis of whole-genome bisulfite-sequencing data}\label{chap:wgbs_statistical_analysis}

\section{Chapter overview}\label{sec:statmodel_chapter_overview}

- [x] DONE

I set out a statistical framework for analysing bisulfite-sequencing data. I begin by explaining the various levels of stochasticity in a methylC-seq experiment. Following this, I define the mathematical notation that I use throughout my thesis. I describe key variables, common estimators of these and their statistical properties. The ideas here are simple, although when extended to their full generality there are several subtleties that must be kept in mind.

In the second half of the chapter I use this framework to discuss downstream analyses of whole-genome bisulfite-sequencing data.

\section{One sample}\label{sec:one_sample}

Even with only a single sample, there are several levels of variation to consider in a bisulfite-sequencing experiment. This variation has a hierarchical structure, which is illustrated in __FIGURE__ and can be separated into pre-sequencing and post-sequencing sources of variation.

\subsection{Pre-sequencing}\label{sec:one_sample_pre_sequencing}

A methylation locus is a single cytosine, that is, a CpG, CHG or CHH. The set of these loci is labelled $\mathcal{I} = \{pos_{i}: i = 1, \ldots, N_{loci} \}$, where $pos_{i}$ is the genomic co-ordinates of the $i^{th}$ locus with respect to the forward strand, e.g. chr1:+:666. I frequently refer to loci by the subscript $i$ rather than by $pos_{i}$. This means that the distance between the $i^{th}$ and $(i + 1)^{th}$ methylation loci varies along the genome and, for a small number of instances, that the $i^{th}$ and $(i + 1)^{th}$ methylation loci are on separate chromosomes. Generally, the number of methylation loci, $N_{loci}$, is not known, although estimates may be made based from the sample or a reference genome. Not knowing the exact value of $N_{loci}$ is no great concern.

The methylation state of a locus can vary within a sample due to cell-to-cell variability of the methylation state. As discussed, a sample in a bisulfite-sequencing experiment contains DNA that is extracted from hundreds or thousands of cells and each cell can have a slightly different methylation profile. Furthermore, within a diploid cell there are two copies of each chromosome, and therefore two copies of each methylation locus, and these two copies can have different methylation states. Therefore, it is also necessary to consider the next level down in the hierarchy; the DNA fragments within the sample.

Suppose that in the pool of DNA fragments for the sample that there are $H_{i}$ fragments containing the $i^{th}$ methylation locus. In general, $H_{i}$ is unknown and will vary from locus to locus within a sample[^H_i]. Note that the value of $H_{i}$ is determined following the library preparation, including PCR amplification of the DNA; therefore, it can give a grossly distorted picture of the true representation of the cells. I denote by $\mathcal{H}_{i}$ the set of all fragments containing the $i^{th}$ locus.

[^H_i]: Knowing $H_{i}$ would require knowing: (1) the number of cells used as input (which might only be known to within an order of magnitude), (2) the ploidy of each cell (generally known) and (3) the number of PCR cycles (generally known). But the real problem is that none of the steps in creating the pool of DNA fragments is perfect. In particular, PCR introduces biases -- some molecules are preferentially amplified while others 'drop out'. So even if we knew (1), (2) and (3) we cannot simply multiply these together to compute $H_{i}$, although this might at least give us a rough estimate.

Although we do not know the number of fragments in the pool, we can define (and measure) the methylation state of a locus on a single DNA fragment. I denote by the indicator random variable, $Z_{h, i}$, the methylation state of $i^{th}$ methylation locus on the $h^{th}$ DNA fragment:

\begin{equation*}
Z_{h, i} = \left\{
  \begin{array}{l l}
    1 & \quad \text{if methylated on the } h^{th} \text{ fragment}\\
    0 & \quad \text{if unmethylated on the } h^{th} \text{ fragment}
  \end{array} \right.
\end{equation*}

By summing over the number of fragments containing the $i^{th}$ locus, we obtain the number of fragments that are methylated at the $i^{th}$ locus ($M_{i}$) and unmethylated at the $i^{th}$ locus ($U_{i}$):

\begin{align*}
  M_{i} &= \sum_{h = 1}^{H = H_{i}} Z_{h, i} = |\{Z: Z \in \mathcal{H}_{i}, Z = 1 \}| \\
  U_{i} &= \sum_{h = 1}^{H = H_{i}} (1 - Z_{h, i}) = |\{Z: Z \in \mathcal{H}_{i}, Z = 0 \}|
\end{align*}

From these we can compute the proportion of fragments that methylated at the $i^{th}$ locus:

\begin{equation*}
  B_{i} = \frac{M_{i}}{M_{i} + U_{i}}
\end{equation*}

The above definitions can be extended to individual methylation loci, 1-tuples, to m-tuples. Mathematically, an m-tuple is denoted by a sequence of methylation loci, $(i, i + 1, \ldots, i + m - 1)$.

I denote by the vector of indicator random variables, $Z_{h, (i, i + 1, \ldots, i + \text{m} - 1)}$, the methylation pattern of the m-tuple $(i, i + 1, \ldots, i + m - 1)$ on the $h^{th}$ DNA fragment containing the m-tuple $(i, i + 1, \ldots, i + \text{m} - 1)$:

\begin{equation*}
Z_{h, i} = \left\{
  \begin{array}{l l}
  (0, 0, \ldots, 0) & \quad \text{if unmethylated at the } i^{th}, (i + 1)^{th}, \ldots, (i + \text{m} - 1)^{th}) \text{ locus on the } h^{th} \text{ fragment}\\
  (0, 0, \ldots, 1) & \quad \text{if unmethylated at the } i^{th}, (i + 1)^{th}, \ldots, (i + \text{m} - 2)^{th}) \text{ locus and methlyated at the } (i + \text{m} - 1)^{th} \text{ locus on the } h^{th} \text{ fragment} \\
  \vdots \\
  (1, 1, \ldots, 1) & \quad \text{if methylated at the } i^{th}, (i + 1)^{th}, \ldots, (i + \text{m} - 1)^{th}) \text{ locus on the } h^{th} \text{ fragment}
  \end{array} \right.
  \end{equation*}

$\mathcal{H}_{(i, i + 1, i + m - 1)}$ denotes the set of all fragments containing the m-tuple $(i, i + 1, i + m - 1)$ and $\mathcal{R}_{(i, i + 1, i + m - 1)}$ denotes the set of all reads containing the m-tuple $(i, i + 1, i + m - 1)$.

There are $2^{\text{m}}$ possible methylation patterns at an m-tuple. Rather than describe a methylation pattern by a m-vector of zeros and ones, I also write these using $U$ and $M$; for example, the possible methylation patterns at a 2-tuple are $MM, MU, UM$ and $UU$.

Analogous to the definition of $M_{i}$ and $U_{i}$ for 1-tuples ($\text{m} = 1$), we have when $\text{m} = 2$:

  \begin{align*}
  MM_{(i, i + 1)} &= |\{Z: Z \in \mathcal{H}_{(i, i + 1)}, Z = (1, 1)\}| \\
  MU_{(i, i + 1)} &= |\{Z: Z \in \mathcal{H}_{(i, i + 1)}, Z = (1, 0)\}| \\
  UM_{(i, i + 1)} &= |\{Z: Z \in \mathcal{H}_{(i, i + 1)}, Z = (0, 1)\}| \\
  UU_{(i, i + 1)} &= |\{Z: Z \in \mathcal{H}_{(i, i + 1)}, Z = (0, 0)\}| \\
  \end{align*}

We could extend the $B_{i}$ values to m-tuples, although the intuitive interpretation of these as the average methylation level is lost. Instead, it reflects the relative frequencies of each methylation pattern. Here are the definitions for $\text{m} = 2$:

  \begin{align*}
  B_{(i, i + 1)}^{MM} &= \frac{MM_{(i, i + 1)}}{MM_{(i, i + 1)} + MU_{(i, i + 1)} + UM_{(i, i + 1)} + UU_{(i, i + 1)}} \\
  B_{(i, i + 1)}^{MU} &= \frac{MU_{(i, i + 1)}}{MM_{(i, i + 1)} + MU_{(i, i + 1)} + UM_{(i, i + 1)} + UU_{(i, i + 1)}}  \\
  B_{(i, i + 1)}^{UM} &= \frac{UM_{(i, i + 1)}}{MM_{(i, i + 1)} + MU_{(i, i + 1)} + UM_{(i, i + 1)} + UU_{(i, i + 1)}}  \\
  B_{(i, i + 1)}^{UU} &= \frac{UU_{(i, i + 1)}}{MM_{(i, i + 1)} + MU_{(i, i + 1)} + UM_{(i, i + 1)} + UU_{(i, i + 1)}}
  \end{align*}

The definitions for $\text{m} > 2$ follow in the obvious manner.

Again, I emphasise that $H_{(i, i + 1, i + \text{m} - 1), j}, Z_{h, (i, i + 1, i + \text{m} - 1), j}, B_{(i, i + 1, i + \text{m} - 1), j}$ and the set of methylation patterns are unobservable. However, by sequencing the pools of DNA fragments we aim to estimate these variables.

\subsection{Post-sequencing}\label{sec:one_sample_post_sequencing}

In a whole-genome bisulfite-sequencing experiment we do not sequence every DNA fragment in the pool. Rather, sequencing can be thought of as sampling without replacement from the pool of DNA fragments. We have a large number(~$10^{10}$) of fragments in the pool and each methylation locus is only present on a small number of those fragments. Therefore, we can approximate this sampling by Poisson sampling, where the rate parameter for locus $i$ is proportional to the number of fragments in the pool and inversely proportional to $H_{i}$.

At this point I ignore reads that do not contain any methylation loci as these are not relevant to this discussion and I make three simplifying assumptions:

1. Sequencing is performed without error.
2. Read mapping is perfect.
3. We perform single-end sequencing.

The effect of the first two assumptions are discussed in Section \ref{sec:mapping_and_post-processing}. The effect of the third assumption is minor. When using single-end sequencing, the methylation loci from a single read will always form a positively ordered sequence without gaps, i.e., $(i, i + 1, i + 2)$ and not $(i, i - 1, i - 2)$ nor $(i, i + 1, i + 3)$. However, when using paired-end sequencing the methylation loci from a paired-end read will still be an ordered sequence but one of the following may occur (__FIGURE__):

1. There may be gaps due to the insert size being longer than the sum of the read lengths, e.g. $(i, i + 1, i + 3, i + 4))$. In effect, we have missing data for any intervening methylation loci; the $(i + 2)^{th}$ loci in this example.
2. Loci may be measured twice if the insert size is less than the sum of the read lengths, e.g. read_1 gives us $(i, i + 1)$ and read_2 gives us $(i + 1, i + 2, i + 3)$. In this example we must use only one of read_1 or read_2 as the measurement of the $(i + 1)^{th}$ locus because otherwise we are 'double-counting'.

Each read measures the methylation state of one or more loci from a single DNA fragment. I denote by $\mathcal{R}_i$ the set of all reads containing the $i^{th}$ locus. Therefore, the number of reads containing the $i^{th}$ locus is $|\mathcal{R}_{i}|$, where $|\mathcal{R}_{i}| \leq H_{i}$ with strict inequality for almost all $i$.

A single read containing the $i^{th}$ locus is denoted $z: z \in \mathcal{R}_{i}$ and the observed methylation state is indicated by:

\begin{equation*}
z: z \in \mathcal{R}_{i} = \left\{
  \begin{array}{l l}
    1 & \quad \text{if methylated at the } i^{th} \text{ locus}\\
    0 & \quad \text{if unmethylated at the } i^{th} \text{ locus}
  \end{array} \right.
\end{equation*}

By summing over the number of reads containing the $i^{th}$ locus we obtain the number of reads that are methylated at the $i^{th}$ locus ($m_{i}$) and unmethylated at the $i^{th}$ locus ($u_{i}$):

\begin{align*}
  m_{i} &= \sum_{z: z \in \mathcal{R}_{i}} z \\
        &= |\{z: z \in \mathcal{R}_{i}, z = 1 \}| \\
  u_{i} &= \sum_{z: z \in \mathcal{R}_{i}} (1 - z) \\
      &= |\{z: z \in \mathcal{R}_{i}, z = 0 \}
\end{align*}

From these we can compute the proportion of reads that are methylated at the $i^{th}$ locus as:

\begin{equation*}
  \beta_{i} = \frac{m_{i}}{m_{i} + u_{i}}
\end{equation*}

These are the so-called $\beta$-values, which are commonly interpreted as an estimate of the proportion of cells in the sample that are methylated at the $i^{th}$ locus. I discuss this interpretation, and other estimators of the  methylation level at a locus, in Section \ref{sec:estimating_B}.

Again, these definitions can be extended from 1-tuples to m-tuples. The set of all reads containing the m-tuple $(i, i + 1, \ldots, i + \text{m} - 1)$ is denoted by $\mathcal{R}_{(i, i + 1, \ldots, i + \text{m} - 1)}$. A single read containing the m-tuple $(i, i + 1, \ldots, i + \text{m} - 1)$ is denoted by $z: z \in \mathcal{R}_{(i, i + 1, \ldots, i + \text{m} - 1)}$, and the observed methylation state is given by:

\begin{equation*}
z: z \in \mathcal{R}_{(i, i + 1, \ldots, i + \text{m} - 1)} = \left\{
  \begin{array}{l l}
    (0, 0, \ldots, 0) & \quad \text{if unmethylated at the } i^{th}, (i + 1)^{th}, \ldots, (i + \text{m} - 1)^{th}) \text{ locus}\\
    (0, 0, \ldots, 1) & \quad \text{if unmethylated at the } i^{th}, (i + 1)^{th}, \ldots, (i + \text{m} - 2)^{th}) \text{ locus and methlyated at the } (i + \text{m} - 1)^{th} \text{ locus} \\
    \vdots \\
    (1, 1, \ldots, 1) & \quad \text{if methylated at the } i^{th}, (i + 1)^{th}, \ldots, (i + \text{m} - 1)^{th}) \text{ locus}
      \end{array} \right.
\end{equation*}

Note that we do not know from which haplotype ($h$) each read came from, only that all methylation loci in the read came from the same DNA fragment.

By counting over the number of reads containing the m-tuple $(i, i + 1, \ldots, i + \text{m} - 1)$ we obtain the number of reads contain each methylation pattern at that m-tuple. Here are the definitions for $\text{m} = 2$:

\begin{align*}
  mm_{(i, i + 1)} &= |\{z: z \in \mathcal{R}_{(i, i + 1)}, z = (1, 1)\}| \\
  mu_{(i, i + 1)} &= |\{z: z \in \mathcal{R}_{(i, i + 1)}, z = (1, 0)\}| \\
  um_{(i, i + 1)} &= |\{z: z \in \mathcal{R}_{(i, i + 1)}, z = (0, 1)\}| \\
  uu_{(i, i + 1)} &= |\{z: z \in \mathcal{R}_{(i, i + 1)}, z = (0, 0)\}|
\end{align*}

We can extend the $\beta_{i}$ values to m-tuples. Here are the definitions for $\text{m} = 2$:

\begin{align*}
  \beta_{(i, i + 1)}^{mm} &= \frac{mm_{(i, i + 1)}}{mm_{(i, i + 1)} + mu_{(i, i + 1)} + um_{(i, i + 1)} + uu_{(i, i + 1)}} \\
  \beta_{(i, i + 1)}^{mu} &= \frac{MU_{(i, i + 1)}}{mm_{(i, i + 1)} + mu_{(i, i + 1)} + um_{(i, i + 1)} + uu_{(i, i + 1)}} \\
  \beta_{(i, i + 1)}^{um} &= \frac{UM_{(i, i + 1)}}{mm_{(i, i + 1)} + mu_{(i, i + 1)} + um_{(i, i + 1)} + uu_{(i, i + 1)}} \\
  \beta_{(i, i + 1)}^{uu} &= \frac{UU_{(i, i + 1)}}{mm_{(i, i + 1)} + mu_{(i, i + 1)} + um_{(i, i + 1)} + uu_{(i, i + 1)}}
\end{align*}

The definitions for $\text{m} > 2$ follow in the obvious manner.

One final definition is the average methylation of each read, which is used by some authors, including \cite{Landan:2012kp}. For each read, $z \in \mathcal{R}_{(i, i + 1, \ldots, i + \text{m} - 1)}$, the average methylation of the read, $\zeta_{z}$, is defined as the proportion of methylation loci in the read that are methylated. Thus, $\zeta_{z} = 0, \frac{1}{m}, \frac{2}{m}, \ldots, 1$.

\subsection{Some complications for a single sample}\label{sec:one_sample_complications}

I now discuss some complications and how this framework might accommodate these issues in practice.

\subsubsection{What is $\mathcal{I}$?}\label{sec:what_is_I}

As mentioned in Chapter \ref{chap:wgbs_bioinformatics_analysis}, studies using bisulfite-conversion assays rely on either a reference genome or, less commonly, separate DNA sequencing of the sample that is assayed. Different analysis strategies lead to different definitions of $\mathcal{I}$, which are approximations to the 'true' set of methylation loci in the sample, $\mathcal{I}^{truth}$. Listed here are definitions of $\mathcal{I}$ from least closely matching to most closely matching $\mathcal{I}^{truth}$:

1. $\mathcal{I}^{ref}$: Defined by the set of methylation loci in the reference genome. This ignore all genetic variation between the sample and the reference.
2. $\mathcal{I}^{refFilter}$: Defined by filtering out problematic loci from $\mathcal{I}^{ref}$. A conservative approach that removes many sites of genetic variation between the sample and the reference as well as sites that do not display genetic variation between the sample and the reference. This approach cannot identify sample-specific methylation loci.
3. $\mathcal{I}^{Bis-SNP}$: Defined by calling genetic variants from the bisulfite-sequencing data using `Bis-SNP` \cite{Liu:2012ge}. Identifies sample-specific methylation loci and removes reference-specific methylation loci. This is the best approach if only bisulfite-sequencing data are available.
4. $\mathcal{I}^{WGS}$: Defined by identifying all methylation loci from _whole-genome sequencing_ (WGS) of the sample's genome. The gold standard. All methylation loci are defined with respect to the sample's genome. The only differences between $\mathcal{I}^{WGS}$ and $\mathcal{I}^{truth} are due to sequencing errors, incomplete sequencing coverage of the sample's genome and variant calling errors from the WGS data.

\subsubsection{Genetic heterozygosity at a methylation locus}\label{sec:heterozygosity}

The genome of a diploid organism has sites that are heterozygous due to differences between the maternal and paternal chromosomes. Such heterozygous loci are sometimes also methylation loci. For example, a locus where the maternal chromosome is a CpG and the paternal chromosome is an ApG. In effect, the maternal and paternal chromosomes within the sample have different $\mathcal{I}^{truth}$.

The number of these genetically heterozygous methylation loci is often small enough not to worry about. However, in some studies, such as those of allele-specific methylation, these loci can be very important and might be identified by calling heterozygous genetic variants using `Bis-SNP` or from WGS of the sample. In practice, the existence of such loci is often ignored.

\section{Multiple samples}\label{sec:multiple_samples}

From a purely notational perspective, the move from a single sample to multiple samples simply requires an additional subscript, $j = 1, \ldots, n$, where $n$ is the number of samples. This defines the three levels in the hierarchy of a typical experiment -- DNA fragments ($h$), methylation loci ($i$) and samples ($j$). For example, $\mathcal{I}_{j}$ is the set of methylation loci in the $j^{th}$ sample and $\beta_{i, j}$ is the beta value for the $i^{th}$ locus in the $j^{th}$ sample.

A fourth level is how the sample's relate to one another, such as the treatment group of each sample. This fourth level might be defined up-front, such as in a designed experiment looking for differences in methylation between tumour and normal tissue. Conversely, the aim of the experiment might be to _discover_ this grouping, such as in a clustering analysis.

We can define this fourth level using a design matrix $X = [X_{j}]$. For example, in a two-group experiment $X_{j} = 1$ if the sample is from group $1$ and $X_{j} = 0$ if the sample is from group $2$. We can also include covariates in the standard way by allowing $X_{j}$ to be a row vector, $X_{j} = (x_{1, j}, \ldots, x_{P, j})$, where $x_{p, j}$ encodes the information on the $p^{th}$ covariate for the $j^{th}$ sample.

\subsection{Some complications with multiple samples}\label{sec{multi_sample_complications}}

In addition to the complications of the Section \ref{sec:one_sample_complications}, we now have sample-to-sample variation that must be addressed by this framework.

\subsubsection{$\mathcal{I}$}

Each sample has their own set of methylation loci, that is, $\mathcal{I}_{j}$ differs between $j$. Furthermore, sequencing coverage varies from sample-to-sample. This means that even if the samples have exactly the same $\mathcal{I}_{j}$, i.e., the samples are genetically identical, each sample will have a different set of loci with 'sufficient' sequencing coverage. Loci without sufficient sequencing coverage are effectively missing data.

In practice, we might choose to study $\mathcal{I}^{common} = \cap_{j} \mathcal{I}_{j}$ or some other intersection of the $\mathcal{I}_{j}$, such as all methylation loci present in at least some fraction of the $n$ samples.

A conservative analysis might only analyse those loci where at least some fraction of the $n$ samples have sufficient sequencing coverage. A less conservative analysis might try to impute the missing values based on methylation levels at neighbouring loci.

\section{Parameter estimation}\label{sec:parameter_estimation}

The main parameter of interest for each sample is the vector of methylation levels for each locus, $\bm{B_{j}}$. To do so it is necessary to estimate $M$ and $U$. In this section I review various methods for estimating these key parameters. When necessary, I have 'translated' the original work into my notation to make these methods more readily comparable. I have suppressed $j$ subscript when referring to a single sample.

\subsection{Estimating $M$, $U$}\label{sec:estimating_m_and_u}

The simplest and most commonly used estimators of $M_{i}$ and $U_{i}$ are $m_{i}$ and $u_{i}$, that is, the number of reads that are methylated and unmethylated at the $i^{th}$ locus, subject to some filtering of the reads and read-positions \citep[e.g.,]{Cokus:2008fc, Lister:2008bh, Lister:2009hy, Lister:2011kg, Hansen:2011gu}). $M_{i}$ and $U_{i}$ may be estimated per-strand or aggregated across strands in the case of palindromic methylation loci. CpG methylation is typically aggregated across strands.

`methtuple` uses this simple method to estimate $MM_{(i, i + 1)}$, $MU_{(i, i + 1)}$, etc., that is, the frequency of methylation patterns at m-tuples.

\subsection{Estimating $B$}\label{sec:estimating_B}

Most analyses of bisulfite-sequencing data have focused on estimating the average methylation level at individual methylation loci, $B_{i}$. The simplest estimator is $\beta_{i} = \frac{m_{i}}{m_{i} + u_{i}}$, which has been widely used \citep[e.g.,]{Cokus:2008fc, Lister:2008bh, Lister:2009hy, Lister:2011kg}).

Under a Binomial model for the number of methylated reads at the $i^{th}$ locus in the $j^{th}$ sample, $M_{i, j} | n_{i, j} \eqd Binomial(n_{i, j}, B_{i, j})$, $\beta_{i, j}$ is the maximum likelihood estimator of $B_{i, j}$. It should be noted that this is conditional on the observed sequencing coverage, $n_{i, j}$.

Recently, more sophisticated methods have been proposed to estimate or model the average methylation level. These methods, which are based on $m_{i, j}$ and $u_{i, j}$, include beta-binomial models \citet{Feng:2014iq, Sun:2014fk, Dolzhenko:2014bo}, and the smoothing-methods proposed by \cite{Hansen:2011gu, Hansen:2012gr, Hebestreit:2013ko}. The aim of these methods isn't necessarily to estimate $B_{i, j}$ - rather, it is typically a step along the way to identify differential methylation - but estimates of $B_{i, j}$ can be obtained if so desired.

\subsubsection{Beta-binomial models}

Several papers have proposed the beta-binomial distribution as a natural model "for describing methylation levels of an individual site across replicates" \cite{Dolzhenko:2014bo}. The 'beta' component of the distribution models the underlying methylation level, $B_{i, j}$, while the 'binomial' component models the sampling of reads by sequencing. Another way to think of this is that the 'beta' component models the biological variability of the data, while the 'binomial' component models the sampling variability of sequencing. This separation of biological and technical variability has proven successful in detecting differential gene expression from RNA-seq data. For example, the `edgeR` software \cite{Robinson:2010cw} uses the negative binomial distribution, which can be thought of as a gamma-poisson mixture distribution, to account for both the biological and sampling variability.

An attractive feature of the beta-binomial distribution is that it can be motivated by, and analysed with, Bayesian methods, including empirical Bayes methods, or frequentist techniques such as maximum likelihood. For example, the software `DSS` \cite{Feng:2014iq} and `MOABS` \citet{Sun:2014fk} both use the beta-binomial distribution in an empirical Bayes analysis of differential methylation from bisulfite-sequencing data. In contrast, `RADmeth` \cite{Dolzhenko:2014bo} uses the beta-binomial model in a maximum likelihood framework to address the same problem.

\subsubsection{Smoothing $\beta$-values}\label{sec:smoothing_beta-values}

`BSmooth`, published in \citet{Hansen:2011gu, Hansen:2012gr} and available in the R/Bioconductor package `bsseq`, and `BiSeq`, published in \citet{Hebestreit:2013ko} and available in the R/Bioconductor package `BiSeq`, take a different approach to getting improved estimates of the $B_{i, j}$. Both `bsseq` and `BiSeq` use statistical smoothing of the 'raw' $\beta_{i, j} = \frac{m_{i, j}}{m_{i, j} + u_{i, j}}$. Smoothing is motivated and justified by the fact that the $B_{i, j}$ are spatially correlated within a sample, i.e., because of the presence of co-methylation (discussed in Chapters \ref{chap:co-methylation} and \ref{chap:co-methylation_review}).

Smoothing is particularly powerful for loci with low sequencing coverage, where the denominator $m_{i, j} + u_{i, j}$ is small and the corresponding standard error of $\beta_{i, j}$ is large. The smoothed $\beta$-values, rather than the raw $\beta$-values, are then generally used in all downstream analyses.

Both `bsseq` and `BiSeq` use a binomial local likelihood smoother. In each case this smoother was chosen because `BSmooth` and `BiSeq` model the number of methylated reads at the $i^{th}$ locus in the $j^{th}$ sample by ($M_{i, j} | n_{i, j}$ \eqd Binom(n_{i, j}, B_{i, j})$. The smoothing is 'local' to exploit co-methylation, which is a local phenomenon.

In both `bsseq` and `BiSeq` the raw $\beta$-values are weighted according to the binomial likelihood and a kernel function. The binomial likelihood weights points inversely to their standard error, $se(\beta_{i, j})$, and the kernel gives greater weight to those $\beta_{i, j}$ near the centre of the window. \citet{Lacey:2013iy} note that loci with very high sequencing coverage will strongly influence the smoother, potentially biasing estimates at neighbouring loci with lower coverage.

`bsseq` assumes that for each sample that the underlying methylation level, $B_{i, j}$, is a smoothly varying function of the position in the genome, $i$. In contrast, `BiSeq` first creates clusters of CpGs and only assumes that the underlying methylation level is smooth at positions within each cluster.

Whenever smoothing is used, a key parameter is the bandwidth, which is the size of the window in which observations are included at each iteration of the smoother. `bsseq` uses a much larger window size than `BiSeq`; the default window size in `bsseq` is one that contains at least 70 CpGs and is at least 2000kb wide, whereas the default window size in `BiSeq` is 80bp, regardless of CpG-density. This is due to `BiSeq` being developed for RRBS data, which has a high CpG-density per window, whereas `bsseq` was developed for whole-genome data, which has a more variable, and lower on average, CpG density per window.

Another 'parameter' choice when smoothing is the choice of kernel, although this is generally less important than the choice of bandwidth. `bsseq` uses a tricube kernel and `BiSeq` uses a triangular kernel.

\citet{Hebestreit:2013ko} and \citet{Lacey:2013iy} compare the smoothing results of `BiSeq` to `bsseq`. Both \citet{Hebestreit:2013ko} and \citet{Lacey:2013iy} provide instances where they claim `BiSeq` gives more 'reasonable' smoothed values than `bsseq`, but the comparison is a little unfair since both use RRBS data, for which `bsseq` is not designed[^rrbs_sim].

[^rrbs_sim]: Both \citet{Hebestreit:2013ko} and \citet{Lacey:2013iy} altered the default `bsseq` parameters to try to make them comparable to `BiSeq`. \citet{Hebestreit:2013ko} changed the default minimum window size to 80bp but still required at least 20 CpGs per window. \citet{Lacey:2013iy} kept the default minimum window size of 2000 bp but reduced the minimum number of CpGs per window to 50 from the default of 70.

\section{Statistical properties of $\beta$-values}\label{sec:beta}

Under the binomial model, ($M_{i, j} | n_{i, j}) \eqd Bin(n_{i, j}, B_{i, j})$, $\beta_{i, j} = \frac{m_{i, j}}{m_{i, j} + u_{i, j}}$ is an unbiased estimator of $B_{i, j}$ with standard error $se(\beta_{i, j}) = \sqrt(\frac{\beta_{i, j}(1 - \beta_{i, j})}{n_{i, j}})$ \citep{Hansen:2012gr}. The natural interpretation of $\beta_{i, j}$ is then as an estimator of the average level of methylation at the $i^{th}$ locus in the $j^{th}$ sample. In this section I discuss this interpretation and statistical properties of this estimator.

\subsection{Distributions}

In a study involving multiple samples, the set of $\beta$-values can be summarised as a matrix where each row is a locus and each column is a sample. Some values will be missing, either because there was insufficient sequencing coverage to estimate a $\beta$-value or because that locus is not a cytosine for that sample. This matrix might be visualised to learn about the distribution of methylation levels, either row-wise, to learn about the variability across samples, or column-wise, to learn about the variability within samples.

Restricting our attention to CpGs, __FIGURE__ shows the column-wise summaries of the EPISCOPE data, that is, the genome-wide distributions of $\beta$-values for each sample. What is immediately clear is that these distributions are bimodal. This bimodality is driven by the fact that CpGs in CpG islands are generally unmethylated whereas those outside of CpG islands are generally methylated, which we can see when we stratify CpGs by their CpG island status.

__UP TO HERE__

__TODO: Using the EPISCOPE data create the following:__

- [ ] Genome-wide density
  - [ ] Stratified by CGI
- [ ] Differences (or correlations) of $\beta$-values between strands



```{r, eval = FALSE, echo = FALSE}
# Run on one of the unices
setwd("/wehisan/home/allstaff/h/hickey/methylation_m-tuples/analyses/processed_data/EPISCOPE")
library(MethylationTuples)
library(ggplot2)
library(dplyr)
library(tidyr)
thesis_theme <- theme_classic(base_size = 12)
thesis_theme <- theme_bw(base_size = 12)

x <- readRDS('EPISCOPE_1_tuples_strand_collapsed.rds')

cgi <- read.table('~/methylation_m-tuples/CGI/model-based-cpg-islands-hg19.txt', header = TRUE, stringsAsFactors = FALSE)
cgi <- GRanges(seqnames = cgi$chr, IRanges(cgi$start, cgi$end))
cgi_status <- overlapsAny(x, cgi)

beta <- methLevel(x, min_cov = 10L)

cn <- colnames(beta)
beta <- data_frame(Individual = rep(substr(cn, 1, 3), each = nrow(beta)),
           Tissue = rep(substr(cn, 4, 6), each = nrow(beta)),
           beta = as.vector(beta),
           CGI = rep(cgi_status, ncol(beta)))

a <- beta[sample(nrow(beta), 100000), ]

ggplot(aes(x = beta), data = a) + 
  geom_density(aes(linetype = Tissue)) + 
  facet_grid(. ~ Individual) +
  thesis_theme

ggplot(aes(x = beta), data = a) + 
  geom_density(aes(linetype = Tissue)) + 
  facet_grid(CGI ~ Individual) +
  thesis_theme



```


To do the same plots for the row-wise summaries would be rather tedious since there are many, many more rows (loci) than columns (samples) in the matrix of $\beta$-values. However, a few examples are shown in __FIGURE__. These row-wise summaries are often modelled by the beta distribution \cite[e.g.,]{Hebestreit:2013ko, Lacey:2013iy}. The Beta distribution is a flexible 2-parameter distribution on $[0, 1]$. It can be unimodal, "U"-shaped or "J"-shaped, depending on the choice of parameters. The Beta distribution also includes the Uniform and arcsine distributions as special cases (__TODO: better source than wikipedia__).

The analysis of the row-wise distributions leads to the analysis of differential methylation and differential variability, which are discussed in __SECTION__.

\subsection{Correlations}

- [x] DONE

Many researchers have observed that DNA methylation is spatially correlated along the genome, \cite[e.g.,]{Eckhardt:2006gh, Cokus:2008fc, Li:2010fb, Hansen:2011gu, Hebestreit:2013ko, Wang:2011cw, Pedersen:2012vl, Lacey:2013iy, Sofer:2013bk, Liu:dy, Lyko:2010dr, Landan:2012kp, Lister:2009hy}). I call this correlation of methylation levels _co-methylation_.

Just as we can explore the distribution of DNA methylation levels within a sample or between samples, so too can we explore co-methylation within a sample or between samples. I examine this in detail in Chapter \ref{chap:co-methylation}

\subsection{Biases}

- [x] DONE

The natural interpretation of $\beta_{i, j}$ as the average level of methylation at the $i^{th}$ locus in the $j^{th}$ sample will be biased if the probability of sequencing a fragment with a methylated site is different from the probability of sequencing a fragment with an unmethylated site. In fact, it has been shown that methylated DNA is overrepresented in bisulfite-sequencing data due, with the problem exacerbated by higher rounds of PCR amplification and dependent on the bisulfite-conversion protocol \cite{Ji:2014fq}. PCR amplification can result in overreprestation of one of the DNA strands in bisulfite-sequencing data \cite{Warnecke:1997eh}.

Lab-based solutions to overcome these biases exist for targeted bisulfite-sequencing, but are technically difficult and expensive to extend to whole-genome studies. \cite{Ji:2014fq} propose potential computational corrections for these biases but as yet these have not been implemented.

\subsection{Transformations}

- [x] DONE

$\beta$-values are the _de facto_ standard unit for reporting methylation levels due to their natural interpretation as an estimate of the average level of methylation at the locus. However, they are not necessarily the best unit for statistical inference. This is because a $\beta$-value is an estimate of a proportion and there are a well-known challenges when working with proportion data, such as:

1. The estimate of the standard error depends on the estimate of the mean (i.e., $\beta$), through $se(\beta) = \sqrt{\frac{\beta (1 - \beta)}{m + u}}$. Taking the derivative of this, we see that the maximum standard error, $\sqrt(\frac{0.25}{m + u})$, occurs at $\beta = 0.5$ and the minimum standard error, $0$, occurs at $\beta = 0, 1$.
2. We need to more than just the $\beta$-value to have a sense of how precise an estimate it is. Essentially, we need to also know the sequencing coverage of the methylation loci. Consider two CpGs, one with $m = 1, u = 3$ and the other with $m = 100$ $u = 300$. Both CpGs have $\beta = 1/4$ but the second CpG is measured with much greater precision. Assuming the binomial model, the first CpG has $se(\beta) = \sqrt{\frac{1/4 \times 3/4}{4}} = 0.22$ whereas the second CpG has $se(\beta) = \sqrt{\frac{1/4 \times 3/4}{400}} = 0.02$.
3. Proportions are bound between 0 and 1, inclusive.

To address (1), proportion data are often transformed via a variance stabilisation transformation. The aim is to make the variance independent of the mean, at least approximately. Popular variance stabilisation transformations include:

- The arcsine transformation, $\arcsin({\sqrt{\frac{m + 1}{m + u + 1}}})$ \citep{ANSCOMBE:1948bw}. A small value, in this case 1, is added to both $m$ and $u$ to avoid $\beta = 0, 1$.
- The "averaged arcsine" transformation, $\arcsin{\sqrt{\frac{m}{m + u + 1}}} + \arcsin{\sqrt{\frac{m + 1}{m + u + 1}}}$ \citep{Freeman:1950bh}. One problem with this transformation is that it does not have a unique inverse \citep{Nunes:2009vj}.

However, the general use of variance stabilising transformations for proportion data has fallen out of favour with the widespread availability of generalised linear model software, in particular for the logistic regression model \cite[e.g.,]{Warton:2011gm}.

One transformation that remains popular, at least in the analysis of DNA methylation microarray data, is the logit-transformation, also known as $\mathcal{M}$-values. An $\mathcal{M}$-value is defined as $logit_{2}(\beta) = \log_{2}(\frac{\beta}{1 - \beta} = \log_{2}\Big ( \frac{m + \alpha}{u + \alpha} \Big )$, where here $m$ and $u$ are the intensities from the methylated and unmethylated probes, respectively, and $\alpha$ is an offset to avoid a numerator or denominator that is zero. Similarly defined $\mathcal{M}$-values, also known as log-ratios, are widely and successfully used in analyses of RNA expression two-colour microarrays \cite[e.g.]{Smyth:2005ta}.

\cite{Du:2010dc} advocate for the use of $\mathcal{M}$-values in statistical analyses of methylation levels from microarray data. The main reason for this is that $\mathcal{M}$-values are approximately _homoscedastic_, i.e., their variances are approximately constant across the full range of $\mathcal{M}$-values. As already noted, the logit-transformation is not the only possible variance-stabilising transformation, but the familiarity of log-ratios to bioinformatics and genomics researchers makes it a favourable choice. Nonetheless, \cite{Du:2010dc} also advocate that the results of analyses should be reported as $\beta$-values, owing to their "more intuitive biological interpretation".

As with $\beta$-values, $\mathcal{M}$-values derived from bisulfite-sequencing data generally cannot be directly analysed due to the variable sequencing coverage across loci. However, the variable sequencing coverage can be accounted for using the afore-mentioned beta-binomial models and related regression models, which are discussed in the next section.


\section{Downstream analyses}\label{sec:downstream}

- [ ] DONE

- Don't rehash the details of Chapter WGBS analysis. Rather summarise these questions as statistical problems in the framework I outline in this chapter.
- DMC: Identify $\bar{B_{i}^{(1)}} \neq \bar{B_{i}^{(2)}}$
- DMR: Identify runs of DMCs
- DVC: Identify $\sigma(B_{i}^{(1)}) \neq \sigma(B_{i}^{(2)})$
- DVR: Identify runs of DVCs

\subsection{What is the genome-wide methylation level?}

This is a simple question with a somewhat complex answer.

- Average (weighted) $\beta$-values.
- Lister's method

\subsubsection{A criticism of ``identifying methylcytosines''}{sec:criticism_of_methylcytosines}

__TODO: Simplify and shorten__

\citet{Lister:2008bh}, one of the first papers to include WGBS data, introduced a method "to identify the presence of a methylated cytosine" (detailed in the supplementary material). This idea was also used in subsequent publications from the same group \citep{Lister:2009hy, Lister:2011kg}[^Lister_2013] with similarly high profiles. I believe that this definition of a "methylcytosine" is an unnecessary source of confusion, as I will explain.

[^Lister_2013]: It is worth noting that this idea was not used in the analysis of WGBS data from more recent paper from the same group \citep{Lister:2013et}.

It is necessary to use scare quotes to distinguish the term 'methylcytosine', as used by \citet{Lister:2008bh, Lister:2009hy, Lister:2011kg}, from the standard definition meaning a 5-methylcytosine. A 'methylcytosine' is a cytosine in the reference genome where "at least s [sic; I believe this should be "a"] subset of the genomes within the sample were methylated" \citep[supplementary material]{Lister:2009hy}. Thus, the idea of identifying 'methylcytosines' is to determine whether each cytosine in the reference genome displays any evidence of methylation in the sample.

The exact procedure is not mathematically described in any of \citet{Lister:2008bh, Lister:2009hy, Lister:2011kg}. The earliest of these papers, \citet{Lister:2008bh}, includes a short non-mathematical description, while the most detailed description is given in the supplementary material of \citet{Lister:2009hy}. \citet{Lister:2011kg} simply refers to \citet{Lister:2009hy}. Because the written descriptions are unclear, and no code is provided to implement the idea, I am unable to determine exactly what was done. What follows is my interpretation based on what is described in \citet{Lister:2008bh, Lister:2009hy, Lister:2011kg}.

The idea is to test the null hypothesis that the observed number of methylated reads at the $i^{th}$ cytosine were simply due to 'error', where the 'error' is a combination of the estimated sequencing error and the estimated bisulfite-converstion error. Effectively, \citeauthor{Lister:2008bh} are testing the null hypothesis that $\beta_{i, j} = 0$ against the one-side alternative, $\beta_{i, j} > 0$. Any site where the null hypothesis is rejected is declared a 'methylcytosine'. For each cytosine compute a P-value, $P_{i} = \sum_{k = m_{i} + 1}^{k = m_{i} + u_{i}} Prob(X = k)$, where $X = Binom(u_{i} + m_{i}, \epsilon))$ and $\epsilon$ is the estimated 'error'. Then, apply a false discovery rate correction to the resulting $P_{i}$ and declare all cytosines with a FDR-adjusted $P_{i}$ less than some nominal value[^nominal_fdr] to be "methylcytosines".

[^nominal_fdr]: \citet{Lister:2008bh} used an FDR-adjusted P-value cutoff of $0.05$; \citet{Lister:2009hy} used an FDR-adjusted P-value cutoff of $0.01$. I presume the FDR-adjustment to be based on the Benjamini-Hochberg procedure \citep{Benjamini:1995ws}, although this is not explicitly stated.

The $\epsilon$ are estimated on a per-sample basis, with bisulfite-conversion error estimated from the unmethylated chloroplast genome \citep{Lister:2008bh} or from the genome of the lambda phage spike-in control \citep{Lister:2009hy, Lister:2011kg}. It is not clear how the sequencing error rate was estimated, particularly given that the base qualities are not included in the data available from the website.

This procedure was performed separately for each methylation context in \citet{Lister:2009hy}, but it is not clear if this is the case for \citet{Lister:2008bh} (a study of _A. thaliani_, which has large amounts of non-CG methylation) or \citet{Lister:2011kg} (a study that includes pluripotent human cell lines that have non-negligible levels of non-CG methylation). This  affects the false discovery rate correction since the number of tests is far greater if all cytosines are simultaneously corrected compared to a separate correction for each context.

Now to why I don't think this is a very useful procedure. Firstly, this isn't actually estimating the number of methylcytosines in the sample; it is estimating the number of "methylcytosines", which are cytosines in the reference genome that appear to be methylated in at least some subset of the sample. These are two different things. If you want to estimate the number of methylcytosines then a better estimator is based on $\frac{1}{N_{loci}} \sum_{i = 1}^{N_{loci}} \beta_{i}$. A simple example makes this clear.

Suppose we have ten cytosines in our reference sequence, each with a true methylation level of $B_{i} = 0.4$ in our sample, which contains multiple cells of known ploidy. Then the true number of methylcytosines is $0.4$ multiplied by the number of cells in our sample multiplied by the ploidy. We can estimate this by computing the average $\beta_{i}$ (an estimate of the average $B_{i}$) and multiplying it by an estimate of the number of molecules and the (known) ploidy. From this system we could easily generate sequencing data where the observed $\beta$-values are all "significantly" non-zero and thus, according to Lister et al.'s procedure, every cytosine is classified as a "methylcytosine".

Secondly, \citet{Lister:2008bh, Lister:2009hy, Lister:2011kg} use only those cytosines that are classified as "methylcytosines" in many downstream analyses or use the 0-1 classification rather than the actual $\beta$-values. For example, in \citet[supplementary figure 2a]{Lister:2009hy} they use a Venn diagram to compare the number of "methylcytosines" called in two biological replicates to summarise the concordance between the two biological replicates. A far better summary of the biological replicability is to plot the $\beta$-values from each replicate against one another as a scatter plot, as this includes the magnitude of the $\beta$-values and not just whether they are "non-zero".

Another example is that only cytosines identified as "methylcytosines" in at least one sample were used in differential methylation analyses \citep{Lister:2009hy, Lister:2011kg}. While there are often good reasons for screening loci prior to differential testing \citep[e.g.]{Bourgon:2010cr}, this could potentially bias results when looking for regions of differential methylation. For example, suppose there are ten cytosines in a row where the first three and last three are differentially methylated. If we ignore the four intervening cytosines, which are not differentially methylated, then we falsely conclude that the entire region is differentially methylated rather than it being two smaller DMRs.



\section{Dump from previous chapter}

\section{Identifying differential methylation}\label{sec:identifying_differential_methylation}

Identifying differential methylation means to discover sites (differentially methylated cytosines or _DMC_s) or regions (differentially methylated regions or _DMR_s) in the genome that have different levels of methylation between two or more conditions. Much of the methodology for identifying differential methylation has focused on two-group experiments and a somewhat restricted definition: differential methylation is the difference in __average__ methylation between __two__ groups. This is analogous to identifying differential gene expression, which focuses on identifying genes that have different __average__ expression levels between two groups.

While bisulfite-sequencing experiments with multiple groups have been performed and analysed \citep[e.g.,]{Lister:2009hy, Hansen:2011gu, Hansen:2013eo}), these have typically been done using a series of pair-wise comparisons or by comparing each sample in turn against some 'baseline' sample. This is because the analysis of a pair-wise comparison is relatively simple and because it is also generally easier to interpret a two-group comparison than a multi-group comparison. However, as the number of groups increases it becomes more difficult to interpret multiple pair-wise comparisons.

Like when trying to answer any scientific question, the experimental design is very important in order to reliably infer differential methylation. Identifying DMCs is relatively straightforward statistical problem, since it amounts to the well-studied problem of testing the difference of means. However, identifying DMRs, which may or may not build upon an initial scan for DMCs, is a far more challenging statistical problem owing to the high spatial dependence of methylation at neighbouring cytosines (discussed in Chapter \ref{chap:co-methylation}) and the uneven spacing of cytosines throughout the genome.

\subsection{Experimental design}\label{sec:experimental_design}

In any experiment of differential methylation we want the DMCs and DMRs to be both _biologically_ and _statistically_ significant; it's no good if all the differences are simply due to technical artefacts or random fluctuations. Key to ensuring biological relevance is good experimental design, such as the use of _replicates_ in each experimental group. A distinction is often made between _technical replicates_ and _biological replicates_. Briefly, biological replicates are experimental units that all undergo the same treatment and are used to estimate the within-group variability of the treatment. Technical replicates are repeated measurements of the same experimental unit, perhaps with slight variations in the sample preparation, and are used to estimate the variability of the sample preparation and measurement process.

As is clear from this definition, the boundary between biological and technical replication is often a fuzzy one. For example, \cite{Lister:2009hy} state that, "_For each cell type, two __biological__ replicates were performed with cells of different passage number_" (emphasis mine). I contend that these are better defined as technical replicates since each replicate came from the same cell line, underwent passaging under near-identical conditions and differ only by the number of cell passages in each media[^cell_passaging].

[^cell_passaging]: In the case of IMR90 cell line, the first replicate, IMR90_r1, underwent 4 cell passages and the second replicate, IMR90_r2, underwent 5 cell passages. In the case of the H1 cell line, the first replicate, H1_r1, underwent 25 passages in the first media and 9 passages in the second media, and the second replicate, H1_r2, underwent 27 passages in the first media and 5 passages in the second media.

Unfortunately, early experiments with whole-genome bisulfite-sequencing frequently had no replicates of any kind, as is the case of the H9 and IMR90-iPSC cell lines in \cite{Lister:2009hy}. Moreover, even when replicates were performed they were frequently pooled pooled prior to analysis, thus ignoring all within-group variability.

Ideally, variability between technical replicates should be orthogonal to the biological question, but this rarely occurs. Indeed, high-throughput sequencing experiments are particularly susceptible to batch effects, and other sources of unwanted variation, that can swamp the biological variation of interest \citep{Leek:2010jq}. Again, this emphasises the importance of good experimental design.

\subsection{DMCs}\label{sec:dmcs}

There have been reports of differential methylation at individual CpGs resulting in a phenotypic difference \cite{Furst:2012gh}. However, with approximately 25 million CpGs in the human genome, not to mention the many, many more non-CpG cytosines, it is an optimist who aims for the reliable detection of DMCs from WGBS experiments with sample sizes you can count on one or two hands and average sequencing depth of $10-30\times$.

Identifying DMCs boils down to identifying differences in means. As such, it can be readily framed as a 'stand-alone' test, such as a t-test, or cast into a regression framework. There is an enormous body of statistical literature on testing for differences in means.

Regardless of the test used, all attempts to identify DMCs from whole-genome bisulfite-sequencing data must pay a large multiple-hypothesis testing penalty. Correcting for multiple hypothesis testing is standard practice in the analysis of genomics data. but the sheer number of tests, in this case approximately 25 million, is at least an order of magnitude greater than commonly tested in other genomics experiments (e.g., approximately 1 million tests in genome-wide association studies and 20,000 tests in studies of differential gene expression).

However, when identifying DMCs, the _effective_ number of tests is generally fewer due to the high degree of dependence of methylation at neighbouring methylation loci, which ensures a high degree of dependence amongst the tests.

__TODO: What techniques can be used to do FDR, multiple hypothesis testing? Are standard tools applicable in such high-dependence settings?__

\subsubsection{One-group tests}\label{sec:one_group_dmcs}

The one-group WGBS experiment is uncommon and the $A^{vy}$ experiment described in Chapter \ref{chap:Avy} is the only example that I know of. In a one-group experiment a DMC is one where at least one of the samples has a different methylation level to the group average. Mathematically, we wish to test the null hypothesis  $H_{0}: \beta_{i, j} = \beta_{i, 0}$ for $j = 1, \ldots, n$ against the alternative that $H_{A}: \beta_{i, j} \neq \beta_{i, 0}$ for some $j$, where $\beta_{i, 0}$ may be pre-specified or estimated from the data by, for example, the group average $\frac{1}{n} \sum_{j = 1}^{n} \beta_{i, j}$). This can be tested in a number of ways as I will demonstrate.

The data for the $i^{th}$ methylation locus can be summarised by a $2 \times n$ contingency table, as shown below (__TODO: Prettify table with `booktabs`__)

\begin{table}[h]
\centering
\caption{$2 \times n$ contingency table summarising the methylation evidence for the $i^{th}$ methylation locus in a one-group experiment.}
\label{my-label}
\begin{tabular}{c c c}
\hline
& m          & u          \\ \hline
$Sample_{1}$ & $m_{i, 1}$ & $u_{i, 1}$ \\
$\vdots$     & $\vdots$   & $\vdots$   \\
$Sample_{n}$ & $m_{i, n}$ & $u_{i, n}$ \\
\end{tabular}
\end{table}

Such contingency tables can be analysed in many different ways. Here I apply a few methods to highlight their similarities and differences. Firstly, here are some example data for a single CpG:

```{r}
x <- cbind(M = c(38, 79, 59, 69, 44), U = c(1, 2, 1, 2, 46))
names(dimnames(x)) <- c("sample", "meth_state")
x
```

We see that while `sample_1, ..., sample_4` are nearly completely methylated at this CpG, `sample_5` has approximately $50\%$ methylation, which may be indicative of allele-specific methylation.

In my analysis of the $A^{vy}$ experiment I used the `prop.test` function in R. As documented in the help page for `prop.test`:

> `prop.test` can be used for testing the null that the proportions (probabilities of success) in several groups are the same

in R to test the equality of the proportions ($\beta$-values) across the five mice.

```{r}
prop.test(x)
```

As expected, this test returns a very small P-value, `r print(format.pval(prop.test(x)$p.value), quote = FALSE)`.

What might not be clear from its name is that `prop.test(x)` is just performing Pearson's $\chi^{2}$-test of the null hypothesis that the joint distribution of the cell counts in the $2 \times n$ contingency table is the product of the row and column marginals. This can be seen by examining the source code or by comparing the output to `chisq.test(x)`: (__TODO: Check by hand__)

```{r}
chisq.test(x)
```

Instead of using the "stand-alone" tests, `prop.test` and `chisq.test`, we could explicitly frame this as a log-linear model and test the goodness-of-fit of the "no interaction" model using either the likelihood ratio statistic (`lrt`) or the Pearson's $\chi^{2}$ test statistic (`pearson`). Formally, the regression model is (__TODO: Write down the regression model__):

This model can be fit using the `loglin` function in R or using the arguably more user-friendly `loglm` (from the `MASS` package) or `glm` functions:

```{r}
# Using loglin
loglin(x, margin = list(1, 2))
# Using loglm
library(MASS)
loglm(formula =  ~ sample + meth_state, data = x)
# Using glm (1)
glm(x ~ 1, family = binomial)
# Using glm (2)
glm(x[,1] / (x[, 1] + x[, 2]) ~ 1, family = binomial, weights = x[,1] + x[, 2])
# TODO: Write sentence summarising output.
```

A key advantage of using regression is the option to include additional covariates in the model, such as the sex of each sample or terms to account for batch effects. __TODO: How to do this using `loglin`?__

More complex regression analyses are possible, such as empirical Bayes or fully Bayesian models. I describe these in more detail in discussing two-group and multi-group experiments, but they may also be applied to one-group experiments.

A proper software implementation needs to take care of issues such as incomplete tables and non-convergence of the iterative proportional scaling algorithm used by `loglin`. Speed is also important when performing this many tests and the regression based approaches are much slower, at least when naively applied, due to additional checks they make of the data:

```{r}
# Basic benchmarking
library(microbenchmark)
print(microbenchmark(prop.test(x), chisq.test(x), loglin(x, margin = list("sample", "meth_state")), loglm(formula = ~ sample + meth_state, data = x), glm(x ~ 1, family = binomial), glm(x[,1] / (x[, 1] + x[, 2]) ~ 1, family = binomial, weights = x[,1] + x[, 2]), glm.fit(x = matrix(, nrow(x), 0L), y = x, family = binomial()), times = 100), order = "median")
```

\subsubsection{Two-group experiments}\label{sec:two_group_dmcs}

In a two group experiment, for each methylation locus we are testing the hypothesis that the average methylation level in the first group, $\bar{\beta_{i}^{(1)}}$, is different to that in the second group, $\bar{\beta_{i}^{(2)}}$.

If there are no replicates in either group[^2x2] then we have a $2 \times 2$ contingency table:

[^2x2]: I'd argue that this is a two-sample experiment rather than a two-group experiment since each group has $n = 1$.

(__TODO: Prettify table with `booktabs`__)

\begin{table}[h]
\centering
\caption{$2 \times 2$ contingency table summarising the methylation evidence for the $i^{th}$ methylation locus in a two-group experiment with no replicates in either group.}
\label{my-label}
\begin{tabular}{c c c}
\hline
& m          & u          \\ \hline
$Group_{1}$ & $m_{i, 1}$ & $u_{i, 1}$ \\
$Group_{2}$ & $m_{i, 2}$ & $u_{i, 2}$ \\
\end{tabular}
\end{table}

This $2 \times 2$ table is then tested for independence of the rows and columns. As the sample size for each table is often small, Fisher's exact test is generally preferable since, unlike Pearson's $\chi^{2}$ test, the P-values are _exact_, meaning they do not rely on large-sample approximations (__CITE: Agresti__). Fisher's exact test is a _conditional_ test because the null distribution (a hypergeometric distribution) is derived by conditioning on both the marginal totals. __CITE: Agresti__ discusses the arguments for and against conditional and unconditional tests of independence in the $2 \times 2$ table.

The more interesting experiment is one that includes replicates within each group, since we can then estimate the within-group variation. Unfortunately, some authors have used Fisher's exact test to analyse experiments including replicates (__TODO: Highlight papers that have inappropriately used Fisher's exact test; does Lister 2013 inappropriately pool then test?). This is incorrect because it effectively aggregates all the counts within each group and so ignores all within-group biological variability \citep{Hansen:2012gr}.

Instead, a test that incorporates the within-group variability should be used.  For example, we could use a t-test to compare the average methylation level in the first group, $\bar{\beta_{i}^{(1)}}$, to that in the second group, $\bar{\beta_{i}^{(2)}}$. Several methods have been proposed for testing for DMCs. These methods differ considerably in how they model and transform the data as well as what test statistic is used to identify DMCs.

\paragraph{Transforming}\label{sec:transforming}

Smoothing of the $\beta$-values has been used advocated by several authors to remove variation due to low sequencing coverage and to exploit the spatial correlation of DNA methylation \citep{Hansen:2011gu, Hebestreit:2013ko, Gokhman:2014c}. Both `BSmooth` \citep{Hansen:2012gr} and `BiSeq` \citep{Hebestreit:2013ko} smooth the $\beta$-values using a binomial local likelihood smoother. \citet{Lister:2011kg, Gokhman:2014cp} used a simpler moving average in windows along the genome.

\paragraph{Modeling}\label{sec:modeling}

`DSS` \citep{Feng:2014iq}, `BiSeq` \citep{Hebestreit:2013ko}, `MOABS` \citep{Sun:2014fk} `methylSig` \citep{Park:2014ho} and `RADmeth` \citep{Dolzhenko:2014bo} are software packages that all use a Beta-Binomial hierarchical model of DNA methylation, although the exact details differ considerably between packages. Broadly, under the Beta-Binomial model the "true" methylation level at the $i^{th}$ methylation locus in the $k^{th}$ group is modeled as a Beta random variable, $B_{i, k} = Beta(\mu_{i, k}, \theta_{i, k})$. The observed number of methylated reads at the $i^{th}$ methylation locus, in the $j^{th}$ sample is modeled as a Binomial random variable, $M_{i, j, k} | B_{i, k}, n_{i, j, k} = Binomial(n_{i, j, k}, B_{i, k}), which is conditional on the unobserved $B_{i, k}$ and the observed sequencing coverage, $n_{i, j, k}$.

\paragraph{Estimating and testing}\label{sec:estimating_and_testing}

`DSS` and `MOABS` use empirical Bayes methods to estimate parameters whereas `methylSig`, `BiSeq` and `RADmeth` use maximum likelihood estimation. The test used to identify DMCs is variously a Wald test (`BiSeq`, `DSS`), likelihood ratio test (`methlySig`, `RADmeth`) or based on the credible interval (Bayesian confidence interval) of the difference in methylation between the two groups (`MOABS`).

\subsubsection{Multi-group experiments}\label{sec:multigroup_dmcs}


\subsection{DMRs}

There are two very different strategies for identifying differentially methylated regions:

1. Use regions that are defined _a priori_, which are then tested for differential methylation. Such regions might be CpG islands (__CITE__), MspI restriction fragments (__CITE__) gene promoters (__CITE__) or predefined bins (e.g. 3bp tiles [Bing Ren] or 100bp tiles \citep{Park:2014ho}).
2. Use regions that are defined based on the data, which are then tested for differential methylation. Valid statistical inference of such regions is __very challenging__.

\subsubsection{Using _a priori_ regions}\label{sec:a_prior_regions}

The methylation level is summarised at the region level and then compared across groups. For example, the average of the $\beta$-values across the region may be compared between groups using a t-test.

__TODO: Describe the above mathematically__

This is qualitatively similar to identifying differentially methylated cytosines.

__PROS__

* Simple to implement
* Valid statistical properties

__CONS__

* Doesn't account for differential CpG density across regions
* What is the right "unit" - the CGI, the promoter, a tile???
* Doesn't account for spatial correlation of methylation


\subsubsection{Using data-driven regions}\label{sec:data_driven_regions}


__PROS__

* Can discover the right "unit".
* Might account for spatial correlation of methylation

__CONS__

* Loss of statistical properties in testing, e.g. FDR control
* Bloody hard

\section{Other downstream analyses}\label{sec:other_downstream_analyses}

Bisulfite-sequencing data are used to address a variety of questions apart from identifying differential methylation. Not all these analyses require statistical inference. For example, if we are interested in knowing whether the promoter of a particular gene is methylated in our sample then it may be sufficient to simply plot the level of methylation at each CpG in the region.

However, once we move to experiments with multiple samples, multiple regions and more complex questions then statistical methods are generally required to distinguish the signal from the noise. In this section I briefly describe other

__TODO: Any other important downstream analyses worth mentioning?__

\subsection{Variably methylated regions and differential variability}\label{sec:vmrs}

\subsection{Allele-specific methylation}\label{sec:asm}

\subsection{Methylation entropy}\label{sec:methylation_entropy}

\subsection{Epipolymorphism}\label{sec:epipolymorphism}

\subsection{Epiallele detection}\label{sec:epialleles}

\subsection{Integrating DNA methylation data with other genomes data}\label{sec:data_integration}

\subsection{General computational considerations}

- Using integers instead of floats/doubles



\section{General TODOs}

* Autocorrelation or correlation?
* Discuss distribution of coverage? Perhaps in context of sequencing bias?
* See https://github.com/brentp/clustermodel/README.md for a nice, brief summary of the main DMR calling approaches.
